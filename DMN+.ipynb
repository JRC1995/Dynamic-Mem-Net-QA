{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING PREPROCESSED DATA\n",
    "\n",
    "Loading GloVe word embeddings. Building functions to convert words into their vector representations and vice versa. Loading babi induction task 10K dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from __future__ import division\n",
    "\n",
    "filename = 'glove.6B.100d.txt'\n",
    "\n",
    "def loadEmbeddings(filename):\n",
    "    vocab = []\n",
    "    embd = []\n",
    "    file = open(filename,'r')\n",
    "    for line in file.readlines():\n",
    "        row = line.strip().split(' ')\n",
    "        vocab.append(row[0])\n",
    "        embd.append(row[1:])\n",
    "    print('Loaded!')\n",
    "    file.close()\n",
    "    return vocab,embd\n",
    "vocab,embd = loadEmbeddings(filename)\n",
    "\n",
    "\n",
    "word_vec_dim = len(embd[0])\n",
    "\n",
    "vocab.append('<UNK>')\n",
    "embd.append(np.asarray(embd[vocab.index('unk')],np.float32)+0.01)\n",
    "\n",
    "vocab.append('<EOS>')\n",
    "embd.append(np.asarray(embd[vocab.index('eos')],np.float32)+0.01)\n",
    "\n",
    "vocab.append('<PAD>')\n",
    "embd.append(np.zeros((word_vec_dim),np.float32))\n",
    "\n",
    "embedding = np.asarray(embd)\n",
    "embedding = embedding.astype(np.float32)\n",
    "\n",
    "def word2vec(word):  # converts a given word into its vector representation\n",
    "    if word in vocab:\n",
    "        return embedding[vocab.index(word)]\n",
    "    else:\n",
    "        return embedding[vocab.index('<UNK>')]\n",
    "\n",
    "def most_similar_eucli(x):\n",
    "    xminusy = np.subtract(embedding,x)\n",
    "    sq_xminusy = np.square(xminusy)\n",
    "    sum_sq_xminusy = np.sum(sq_xminusy,1)\n",
    "    eucli_dists = np.sqrt(sum_sq_xminusy)\n",
    "    return np.argsort(eucli_dists)\n",
    "\n",
    "def vec2word(vec):   # converts a given vector representation into the represented word \n",
    "    most_similars = most_similar_eucli(np.asarray(vec,np.float32))\n",
    "    return vocab[most_similars[0]]\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open ('embeddingPICKLE', 'rb') as fp:\n",
    "    processed_data = pickle.load(fp)\n",
    "\n",
    "fact_stories = processed_data[0]\n",
    "questions = processed_data[1]\n",
    "answers = np.reshape(processed_data[2],(len(processed_data[2])))\n",
    "test_fact_stories = processed_data[3]\n",
    "test_questions = processed_data[4]\n",
    "test_answers = np.reshape(processed_data[5],(len(processed_data[5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE DATA:\n",
      "\n",
      "FACTS:\n",
      "\n",
      "1)  ['greg', 'is', 'a', 'swan']\n",
      "2)  ['julius', 'is', 'a', 'lion']\n",
      "3)  ['greg', 'is', 'gray', '<PAD>']\n",
      "4)  ['julius', 'is', 'green', '<PAD>']\n",
      "5)  ['brian', 'is', 'a', 'frog']\n",
      "6)  ['bernhard', 'is', 'a', 'rhino']\n",
      "7)  ['brian', 'is', 'white', '<PAD>']\n",
      "8)  ['bernhard', 'is', 'white', '<PAD>']\n",
      "9)  ['lily', 'is', 'a', 'swan']\n",
      "\n",
      "QUESTION:\n",
      "['what', 'color', 'is', 'lily']\n",
      "\n",
      "ANSWER:\n",
      "gray\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "print \"EXAMPLE DATA:\\n\"\n",
    "\n",
    "sample = random.randint(0,len(fact_stories))\n",
    "\n",
    "print \"FACTS:\\n\"\n",
    "for i in xrange(len(fact_stories[sample])):\n",
    "    print str(i+1)+\") \",\n",
    "    print map(vec2word,fact_stories[sample][i])\n",
    "    \n",
    "print \"\\nQUESTION:\"\n",
    "print map(vec2word,questions[sample])\n",
    "print \"\\nANSWER:\"\n",
    "print vocab[answers[sample]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING TRAINING AND VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "train_fact_stories = []\n",
    "train_questions = []\n",
    "train_answers = []\n",
    "val_fact_stories = []\n",
    "val_questions = []\n",
    "val_answers = []\n",
    "\n",
    "p=90 #(90% data used for training. Rest for validation)\n",
    "    \n",
    "train_len = int((p/100)*len(fact_stories))\n",
    "val_len = int(((100-p)/100)*len(fact_stories))\n",
    "\n",
    "train_fact_stories = fact_stories[0:train_len] \n",
    "val_fact_stories = fact_stories[train_len:(train_len+val_len)]\n",
    "\n",
    "train_questions = questions[0:train_len] \n",
    "val_questions = questions[train_len:(train_len+val_len)] \n",
    "\n",
    "train_answers = answers[0:train_len] \n",
    "val_answers = answers[train_len:(train_len+val_len)] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SENTENCE READING LAYER IMPLEMENTED BEFOREHAND \n",
    "\n",
    "Positionally encode the word vectors in each sentence, and combine all the words in the sentence to create a fixed sized vector representation for the sentence.\n",
    "\n",
    "\"sentence embedding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_reader(fact_stories): #positional_encoder\n",
    "    \n",
    "    pe_fact_stories = np.zeros((fact_stories.shape[0],fact_stories.shape[1],word_vec_dim),np.float32)\n",
    "    \n",
    "    for fact_story_index in xrange(0,len(fact_stories)):\n",
    "        for fact_index in xrange(0,len(fact_stories[fact_story_index])):\n",
    "            \n",
    "            M = len(fact_stories[fact_story_index,fact_index]) #length of sentence (fact)\n",
    "            l = np.zeros((word_vec_dim),np.float32) \n",
    "            \n",
    "            # ljd = (1 − j/M) − (d/D)(1 − 2j/M),\n",
    "            \n",
    "            for word_position in xrange(0,M):\n",
    "                for dimension in xrange(0,word_vec_dim):\n",
    "                    \n",
    "                    j = word_position + 1 # making position start from 1 instead of 0\n",
    "                    d = dimension + 1 # making dimensions start from 1 isntead of 0 (1-100 instead of 0-99)\n",
    "                    \n",
    "                    l[dimension] = (1-(j/M)) - (d/word_vec_dim)*(1-2*(j/M))\n",
    "                \n",
    "                pe_fact_stories[fact_story_index,fact_index] += np.multiply(l,fact_stories[fact_story_index,fact_index,word_position])\n",
    "\n",
    "\n",
    "    return pe_fact_stories\n",
    "\n",
    "train_fact_stories = sentence_reader(train_fact_stories)\n",
    "val_fact_stories = sentence_reader(val_fact_stories)\n",
    "test_fact_stories = sentence_reader(test_fact_stories)\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create randomized batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(fact_stories,questions,answers,batch_size):\n",
    "    \n",
    "    shuffle = np.arange(len(questions))\n",
    "    np.random.shuffle(shuffle)\n",
    "    \n",
    "    batches_fact_stories = []\n",
    "    batches_questions = []\n",
    "    batches_answers = []\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    while i+batch_size<=len(questions):\n",
    "        batch_fact_stories = []\n",
    "        batch_questions = []\n",
    "        batch_answers = []\n",
    "        \n",
    "        for j in xrange(i,i+batch_size):\n",
    "            batch_fact_stories.append(fact_stories[shuffle[j]])\n",
    "            batch_questions.append(questions[shuffle[j]])\n",
    "            batch_answers.append(answers[shuffle[j]])\n",
    "            \n",
    "        batch_fact_stories = np.asarray(batch_fact_stories,np.float32)\n",
    "        batch_fact_stories = np.transpose(batch_fact_stories,[1,0,2])\n",
    "        #result = number of facts x batch_size x fact sentence size x word vector size\n",
    "        \n",
    "        batch_questions = np.asarray(batch_questions,np.float32)\n",
    "        batch_questions = np.transpose(batch_questions,[1,0,2])\n",
    "        #result = question_length x batch_size x fact sentence size x word vector size\n",
    "        \n",
    "        batches_fact_stories.append(batch_fact_stories)\n",
    "        batches_questions.append(batch_questions)\n",
    "        batches_answers.append(batch_answers)\n",
    "        \n",
    "        i+=batch_size\n",
    "        \n",
    "    batches_fact_stories = np.asarray(batches_fact_stories,np.float32)\n",
    "    batches_questions = np.asarray(batches_questions,np.float32)\n",
    "    batches_answers = np.asarray(batches_answers,np.float32)\n",
    "    \n",
    "    return batches_fact_stories,batches_questions,batches_answers\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Tensorflow placeholders\n",
    "\n",
    "tf_facts = tf.placeholder(tf.float32, [None,None,word_vec_dim])\n",
    "tf_questions = tf.placeholder(tf.float32, [None,None,word_vec_dim])\n",
    "tf_answers = tf.placeholder(tf.int32,[None])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#hyperparameters\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "hidden_size = 100\n",
    "passes = 3\n",
    "beta = 0.0005 #l2 regularization scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the trainable parameters initialized here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# FORWARD GRU PARAMETERS FOR INPUT MODULE\n",
    "\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=beta)\n",
    "\n",
    "wzf = tf.get_variable(\"wzf\", shape=[word_vec_dim, hidden_size],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                      regularizer= regularizer)\n",
    "uzf = tf.get_variable(\"uzf\", shape=[hidden_size, hidden_size],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                      regularizer=regularizer)\n",
    "bzf = tf.get_variable(\"bzf\", shape=[hidden_size],initializer=tf.zeros_initializer())\n",
    "\n",
    "wrf = tf.get_variable(\"wrf\", shape=[word_vec_dim, hidden_size],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                      regularizer=regularizer)\n",
    "urf = tf.get_variable(\"urf\", shape=[hidden_size, hidden_size],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                      regularizer=regularizer)\n",
    "brf = tf.get_variable(\"brf\", shape=[hidden_size],initializer=tf.zeros_initializer())\n",
    "\n",
    "wf = tf.get_variable(\"wf\", shape=[word_vec_dim, hidden_size],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                     regularizer=regularizer)\n",
    "uf = tf.get_variable(\"uf\", shape=[hidden_size, hidden_size],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                     regularizer=regularizer)\n",
    "bf = tf.get_variable(\"bf\", shape=[hidden_size],initializer=tf.zeros_initializer())\n",
    "\n",
    "# BACKWARD GRU PARAMETERS FOR INPUT MODULE\n",
    "\n",
    "wzb = tf.get_variable(\"wzb\", shape=[word_vec_dim, hidden_size],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                      regularizer=regularizer)\n",
    "uzb = tf.get_variable(\"uzb\", shape=[hidden_size, hidden_size],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                      regularizer=regularizer)\n",
    "bzb = tf.get_variable(\"bzb\", shape=[hidden_size],initializer=tf.zeros_initializer())\n",
    "\n",
    "wrb = tf.get_variable(\"wrb\", shape=[word_vec_dim, hidden_size],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                      regularizer=regularizer)\n",
    "urb = tf.get_variable(\"urb\", shape=[hidden_size, hidden_size],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                      regularizer=regularizer)\n",
    "brb = tf.get_variable(\"brb\", shape=[hidden_size],initializer=tf.zeros_initializer())\n",
    "\n",
    "wb = tf.get_variable(\"wb\", shape=[word_vec_dim, hidden_size],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                     regularizer=regularizer)\n",
    "ub = tf.get_variable(\"ub\", shape=[hidden_size, hidden_size],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                     regularizer=regularizer)\n",
    "bb = tf.get_variable(\"bb\", shape=[hidden_size],initializer=tf.zeros_initializer())\n",
    "\n",
    "\n",
    "# GRU PARAMETERS FOR QUESTION MODULE (TO ENCODE THE QUESTIONS)\n",
    "\n",
    "wzq = tf.get_variable(\"wzq\", shape=[word_vec_dim, hidden_size],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                      regularizer=regularizer)\n",
    "uzq = tf.get_variable(\"uzq\", shape=[hidden_size, hidden_size],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                      regularizer=regularizer)\n",
    "bzq = tf.get_variable(\"bzq\", shape=[hidden_size],initializer=tf.zeros_initializer())\n",
    "\n",
    "wrq = tf.get_variable(\"wrq\", shape=[word_vec_dim, hidden_size],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                      regularizer=regularizer)\n",
    "urq = tf.get_variable(\"urq\", shape=[hidden_size, hidden_size],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                      regularizer=regularizer)\n",
    "brq = tf.get_variable(\"brq\", shape=[hidden_size],initializer=tf.zeros_initializer())\n",
    "\n",
    "wq = tf.get_variable(\"wq\", shape=[word_vec_dim, hidden_size],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                     regularizer=regularizer)\n",
    "uq = tf.get_variable(\"uq\", shape=[hidden_size, hidden_size],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                     regularizer=regularizer)\n",
    "bq = tf.get_variable(\"bq\", shape=[hidden_size],initializer=tf.zeros_initializer())\n",
    "\n",
    "\n",
    "# EPISODIC MEMORY\n",
    "\n",
    "inter_neurons = 1024\n",
    "\n",
    "w1 = tf.get_variable(\"w1\", shape=[hidden_size*4, inter_neurons],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                     regularizer=regularizer)\n",
    "b1 = tf.get_variable(\"b1\", shape=[inter_neurons],\n",
    "                     initializer=tf.zeros_initializer())\n",
    "w2 = tf.get_variable(\"w2\", shape=[inter_neurons,1],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                     regularizer=regularizer)\n",
    "b2 = tf.get_variable(\"b2\", shape=[1],initializer=tf.zeros_initializer())\n",
    "\n",
    "# ATTENTION BASED GRU PARAMETERS\n",
    "\n",
    "wratt = tf.get_variable(\"wratt\", shape=[hidden_size,hidden_size],\n",
    "                        initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                        regularizer=regularizer)\n",
    "uratt = tf.get_variable(\"uratt\", shape=[hidden_size,hidden_size],\n",
    "                        initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                        regularizer=regularizer)\n",
    "bratt = tf.get_variable(\"bratt\", shape=[hidden_size],initializer=tf.zeros_initializer())\n",
    "\n",
    "watt = tf.get_variable(\"watt\", shape=[hidden_size,hidden_size],\n",
    "                       initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                       regularizer=regularizer)\n",
    "uatt = tf.get_variable(\"uatt\", shape=[hidden_size, hidden_size],\n",
    "                      initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                       regularizer=regularizer)\n",
    "batt = tf.get_variable(\"batt\", shape=[hidden_size],initializer=tf.zeros_initializer())\n",
    "\n",
    "\n",
    "# MEMORY UPDATE PARAMETERS\n",
    "# (UNTIED)\n",
    "wt = []\n",
    "bt = []\n",
    "\n",
    "for i in xrange(passes):\n",
    "    wt.append(tf.get_variable(\"wt\"+str(i), shape=[hidden_size*3,hidden_size],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                    regularizer=regularizer))\n",
    "    bt.append(tf.get_variable(\"bt\"+str(i), shape=[hidden_size],\n",
    "                     initializer=tf.zeros_initializer()))\n",
    "\n",
    "\n",
    "# ANSWER MODULE PARAMETERS\n",
    "\n",
    "# GRU PARAMETERS FOR ANSWER MODULE\n",
    "\n",
    "wa_pd = tf.get_variable(\"wa_pd\", shape=[hidden_size*2,len(vocab)],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                     regularizer=regularizer)\n",
    "ba_pd = tf.get_variable(\"ba_pd\", shape=[len(vocab)],\n",
    "                     initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low level api implementation of GRU\n",
    "\n",
    "Returns a tensor of all the hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU(inp,hidden,\n",
    "        wz,uz,bz,\n",
    "        wr,ur,br,\n",
    "        w,u,b,\n",
    "        seq_len):\n",
    "\n",
    "    hidden_lists = tf.TensorArray(size=seq_len,dtype=tf.float32)\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    def cond(i,hidden,hidden_lists):\n",
    "        return i < seq_len\n",
    "    \n",
    "    def body(i,hidden,hidden_lists):\n",
    "        \n",
    "        x = inp[i]\n",
    "\n",
    "        # GRU EQUATIONS:\n",
    "        z = tf.sigmoid( tf.matmul(x,wz) + tf.matmul(hidden,uz) + bz )\n",
    "        r = tf.sigmoid( tf.matmul(x,wr) + tf.matmul(hidden,ur) + br )\n",
    "        h_ = tf.tanh( tf.matmul(x,w) + tf.multiply(r,tf.matmul(hidden,u)) + b )\n",
    "        hidden = tf.multiply(z,h_) + tf.multiply((1-z),hidden)\n",
    "\n",
    "        hidden_lists = hidden_lists.write(i,hidden)\n",
    "        \n",
    "        return i+1,hidden,hidden_lists\n",
    "    \n",
    "    _,_,hidden_lists = tf.while_loop(cond,body,[i,hidden,hidden_lists])\n",
    "    \n",
    "    return hidden_lists.stack()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention based GRU\n",
    "\n",
    "Returns only the final hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_based_GRU(inp,hidden,\n",
    "                        wr,ur,br,\n",
    "                        w,u,b,\n",
    "                        g,seq_len):\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    def cond(i,hidden):\n",
    "        return i < seq_len\n",
    "    \n",
    "    def body(i,hidden):\n",
    "        \n",
    "        x = inp[i]\n",
    "\n",
    "        # GRU EQUATIONS:\n",
    "        r = tf.sigmoid( tf.matmul(x,wr) + tf.matmul(hidden,ur) + br)\n",
    "        h_ = tf.tanh( tf.matmul(x,w) + tf.multiply(r,tf.matmul(hidden,u)) + b)\n",
    "        hidden = tf.multiply(g[i],h_) + tf.multiply((1-g[i]),hidden)\n",
    "        \n",
    "        return i+1,hidden\n",
    "    \n",
    "    _,hidden = tf.while_loop(cond,body,[i,hidden])\n",
    "    \n",
    "    return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Memory Network + Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DMN_plus(tf_facts,tf_questions):\n",
    "    \n",
    "    facts_num = tf.shape(tf_facts)[0]\n",
    "    tf_batch_size = tf.shape(tf_questions)[1]\n",
    "    question_len = tf.shape(tf_questions)[0]\n",
    "    \n",
    "    hidden = tf.zeros([tf_batch_size,hidden_size],tf.float32)\n",
    "    \n",
    "    # Input Module\n",
    "    \n",
    "    tf_facts = tf.nn.dropout(tf_facts,keep_prob)\n",
    "    \n",
    "    # input fusion layer \n",
    "    # bidirectional GRU\n",
    "    \n",
    "    forward = GRU(tf_facts,hidden,\n",
    "                  wzf,uzf,bzf,\n",
    "                  wrf,urf,brf,\n",
    "                  wf,uf,bf,\n",
    "                  facts_num)\n",
    "    \n",
    "    backward = GRU(tf.reverse(tf_facts,[0]),hidden,\n",
    "                   wzb,uzb,bzb,\n",
    "                   wrb,urb,brb,\n",
    "                   wb,ub,bb,\n",
    "                   facts_num)\n",
    "    \n",
    "    backward = tf.reverse(backward,[0])\n",
    "    \n",
    "    encoded_input = forward + backward\n",
    "\n",
    "    # Question Module\n",
    "    \n",
    "    question_representation = GRU(tf_questions,hidden,\n",
    "                                  wzq,uzq,bzq,\n",
    "                                  wrq,urq,brq,\n",
    "                                  wq,uq,bq,\n",
    "                                  question_len)\n",
    "    \n",
    "    #question_representation's current shape = question len x batch size x hidden size\n",
    "    \n",
    "    question_representation = question_representation[question_len-1]\n",
    "    \n",
    "    #^we will only use the final hidden state. \n",
    "\n",
    "    question_representation = tf.reshape(question_representation,[tf_batch_size,1,hidden_size])\n",
    "    \n",
    "    # Episodic Memory Module\n",
    "    \n",
    "    episodic_memory = question_representation\n",
    "    \n",
    "    encoded_input = tf.transpose(encoded_input,[1,0,2])\n",
    "    #now shape = batch_size x facts_num x hidden_size\n",
    "    \n",
    "\n",
    "    for i in xrange(passes):\n",
    "        \n",
    "        # Attention Mechanism\n",
    "        Z1 = tf.multiply(encoded_input,question_representation)\n",
    "        Z2 = tf.multiply(encoded_input,episodic_memory)\n",
    "        Z3 = tf.abs(tf.subtract(encoded_input,question_representation))\n",
    "        Z4 = tf.abs(tf.subtract(encoded_input,episodic_memory))\n",
    "        \n",
    "        Z = tf.concat([Z1,Z2,Z3,Z4],2)\n",
    "        \n",
    "        Z = tf.reshape(Z,[-1,4*hidden_size])\n",
    "        Z = tf.matmul( tf.tanh( tf.matmul(Z,w1) + b1 ),w2 ) + b2\n",
    "        Z = tf.reshape(Z,[tf_batch_size,facts_num])\n",
    "        \n",
    "        g = tf.nn.softmax(Z)\n",
    "        g = tf.reshape(g,[tf_batch_size,facts_num])\n",
    "        g = tf.transpose(g,[1,0])\n",
    "        g = tf.reshape(g,[facts_num,tf_batch_size,1])\n",
    "        \n",
    "        context_vector = attention_based_GRU(tf.transpose(encoded_input,[1,0,2]),\n",
    "                                             hidden,\n",
    "                                             wratt,uratt,bratt,\n",
    "                                             watt,uatt,batt,\n",
    "                                             g,facts_num)\n",
    "        \n",
    "        context_vector = tf.reshape(context_vector,[tf_batch_size,1,hidden_size])\n",
    "        \n",
    "        # Episodic Memory Update\n",
    "        \n",
    "        concated = tf.concat([episodic_memory,context_vector,question_representation],2)\n",
    "        concated = tf.reshape(concated,[-1,3*hidden_size])\n",
    "        \n",
    "        episodic_memory = tf.nn.relu(tf.matmul(concated,wt[i]) + bt[i])\n",
    "        \n",
    "        episodic_memory = tf.reshape(episodic_memory,[tf_batch_size,1,hidden_size])\n",
    "\n",
    "    # Answer module \n",
    "    \n",
    "    # (single word answer prediction)\n",
    "\n",
    "    episodic_memory = tf.reshape(episodic_memory,[tf_batch_size,hidden_size])\n",
    "    episodic_memory = tf.nn.dropout(episodic_memory,keep_prob)\n",
    "\n",
    "    question_representation = tf.reshape(question_representation,[tf_batch_size,hidden_size])\n",
    "    question_representation = tf.nn.dropout(question_representation,keep_prob)\n",
    "    \n",
    "    y_concat = tf.concat([question_representation,episodic_memory],1)\n",
    "    \n",
    "    # Convert to probability distribution\n",
    "    y = tf.matmul(y_concat,wa_pd) + ba_pd\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function, Evaluation, Optimization function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = DMN_plus(tf_facts,tf_questions)\n",
    "\n",
    "\n",
    "# l2 regularization\n",
    "reg_variables = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "regularization = tf.contrib.layers.apply_regularization(regularizer, reg_variables)\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model_output, labels=tf_answers))+regularization\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "model_output = tf.nn.softmax(model_output)\n",
    "\n",
    "#Evaluate model\n",
    "correct_pred = tf.equal(tf.cast(tf.argmax(model_output,1),tf.int32),tf_answers)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "prediction = tf.argmax(model_output,1)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss= 12.900, Accuracy= 0.000\n",
      "Iter 20, Loss= 1.413, Accuracy= 20.312\n",
      "Iter 40, Loss= 1.428, Accuracy= 26.562\n",
      "Iter 60, Loss= 1.457, Accuracy= 25.781\n",
      "\n",
      "Epoch 1, Validation Loss= 1.423, validation Accuracy= 22.400%\n",
      "Epoch 1, Average Training Loss= 3.304, Average Training Accuracy= 25.000%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.425, Accuracy= 22.656\n",
      "Iter 20, Loss= 1.423, Accuracy= 21.094\n",
      "Iter 40, Loss= 1.432, Accuracy= 21.875\n",
      "Iter 60, Loss= 1.444, Accuracy= 20.312\n",
      "\n",
      "Epoch 2, Validation Loss= 1.402, validation Accuracy= 25.500%\n",
      "Epoch 2, Average Training Loss= 1.416, Average Training Accuracy= 25.279%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.421, Accuracy= 27.344\n",
      "Iter 20, Loss= 1.394, Accuracy= 32.812\n",
      "Iter 40, Loss= 1.386, Accuracy= 28.125\n",
      "Iter 60, Loss= 1.402, Accuracy= 25.000\n",
      "\n",
      "Epoch 3, Validation Loss= 1.392, validation Accuracy= 25.100%\n",
      "Epoch 3, Average Training Loss= 1.404, Average Training Accuracy= 25.078%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.394, Accuracy= 30.469\n",
      "Iter 20, Loss= 1.407, Accuracy= 25.000\n",
      "Iter 40, Loss= 1.394, Accuracy= 24.219\n",
      "Iter 60, Loss= 1.403, Accuracy= 26.562\n",
      "\n",
      "Epoch 4, Validation Loss= 1.418, validation Accuracy= 22.400%\n",
      "Epoch 4, Average Training Loss= 1.397, Average Training Accuracy= 25.882%\n",
      "\n",
      "Iter 0, Loss= 1.431, Accuracy= 21.875\n",
      "Iter 20, Loss= 1.388, Accuracy= 25.781\n",
      "Iter 40, Loss= 1.394, Accuracy= 21.875\n",
      "Iter 60, Loss= 1.436, Accuracy= 26.562\n",
      "\n",
      "Epoch 5, Validation Loss= 1.398, validation Accuracy= 27.000%\n",
      "Epoch 5, Average Training Loss= 1.398, Average Training Accuracy= 24.453%\n",
      "\n",
      "Iter 0, Loss= 1.403, Accuracy= 24.219\n",
      "Iter 20, Loss= 1.399, Accuracy= 26.562\n",
      "Iter 40, Loss= 1.412, Accuracy= 24.219\n",
      "Iter 60, Loss= 1.382, Accuracy= 29.688\n",
      "\n",
      "Epoch 6, Validation Loss= 1.394, validation Accuracy= 25.500%\n",
      "Epoch 6, Average Training Loss= 1.398, Average Training Accuracy= 25.513%\n",
      "\n",
      "Iter 0, Loss= 1.398, Accuracy= 22.656\n",
      "Iter 20, Loss= 1.403, Accuracy= 25.781\n",
      "Iter 40, Loss= 1.380, Accuracy= 27.344\n",
      "Iter 60, Loss= 1.325, Accuracy= 35.938\n",
      "\n",
      "Epoch 7, Validation Loss= 1.333, validation Accuracy= 33.900%\n",
      "Epoch 7, Average Training Loss= 1.378, Average Training Accuracy= 28.504%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.355, Accuracy= 30.469\n",
      "Iter 20, Loss= 1.341, Accuracy= 35.938\n",
      "Iter 40, Loss= 1.338, Accuracy= 34.375\n",
      "Iter 60, Loss= 1.325, Accuracy= 38.281\n",
      "\n",
      "Epoch 8, Validation Loss= 1.307, validation Accuracy= 37.800%\n",
      "Epoch 8, Average Training Loss= 1.336, Average Training Accuracy= 33.783%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.303, Accuracy= 36.719\n",
      "Iter 20, Loss= 1.315, Accuracy= 36.719\n",
      "Iter 40, Loss= 1.302, Accuracy= 35.156\n",
      "Iter 60, Loss= 1.296, Accuracy= 38.281\n",
      "\n",
      "Epoch 9, Validation Loss= 1.307, validation Accuracy= 34.400%\n",
      "Epoch 9, Average Training Loss= 1.314, Average Training Accuracy= 35.469%\n",
      "\n",
      "Iter 0, Loss= 1.296, Accuracy= 35.156\n",
      "Iter 20, Loss= 1.244, Accuracy= 38.281\n",
      "Iter 40, Loss= 1.329, Accuracy= 37.500\n",
      "Iter 60, Loss= 1.302, Accuracy= 36.719\n",
      "\n",
      "Epoch 10, Validation Loss= 1.259, validation Accuracy= 39.100%\n",
      "Epoch 10, Average Training Loss= 1.290, Average Training Accuracy= 36.328%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.271, Accuracy= 29.688\n",
      "Iter 20, Loss= 1.239, Accuracy= 39.844\n",
      "Iter 40, Loss= 1.247, Accuracy= 42.188\n",
      "Iter 60, Loss= 1.338, Accuracy= 30.469\n",
      "\n",
      "Epoch 11, Validation Loss= 1.301, validation Accuracy= 32.700%\n",
      "Epoch 11, Average Training Loss= 1.266, Average Training Accuracy= 37.310%\n",
      "\n",
      "Iter 0, Loss= 1.303, Accuracy= 35.156\n",
      "Iter 20, Loss= 1.218, Accuracy= 38.281\n",
      "Iter 40, Loss= 1.250, Accuracy= 32.031\n",
      "Iter 60, Loss= 1.164, Accuracy= 53.125\n",
      "\n",
      "Epoch 12, Validation Loss= 1.235, validation Accuracy= 40.100%\n",
      "Epoch 12, Average Training Loss= 1.245, Average Training Accuracy= 39.922%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.282, Accuracy= 35.938\n",
      "Iter 20, Loss= 1.181, Accuracy= 48.438\n",
      "Iter 40, Loss= 1.243, Accuracy= 37.500\n",
      "Iter 60, Loss= 1.277, Accuracy= 39.844\n",
      "\n",
      "Epoch 13, Validation Loss= 1.262, validation Accuracy= 39.400%\n",
      "Epoch 13, Average Training Loss= 1.236, Average Training Accuracy= 40.938%\n",
      "\n",
      "Iter 0, Loss= 1.320, Accuracy= 34.375\n",
      "Iter 20, Loss= 1.321, Accuracy= 33.594\n",
      "Iter 40, Loss= 1.145, Accuracy= 50.781\n",
      "Iter 60, Loss= 1.189, Accuracy= 44.531\n",
      "\n",
      "Epoch 14, Validation Loss= 1.214, validation Accuracy= 40.300%\n",
      "Epoch 14, Average Training Loss= 1.225, Average Training Accuracy= 41.060%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.204, Accuracy= 43.750\n",
      "Iter 20, Loss= 1.226, Accuracy= 35.156\n",
      "Iter 40, Loss= 1.131, Accuracy= 53.125\n",
      "Iter 60, Loss= 1.208, Accuracy= 39.844\n",
      "\n",
      "Epoch 15, Validation Loss= 1.201, validation Accuracy= 42.000%\n",
      "Epoch 15, Average Training Loss= 1.202, Average Training Accuracy= 42.321%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.154, Accuracy= 42.969\n",
      "Iter 20, Loss= 1.169, Accuracy= 46.094\n",
      "Iter 40, Loss= 1.157, Accuracy= 44.531\n",
      "Iter 60, Loss= 1.117, Accuracy= 45.312\n",
      "\n",
      "Epoch 16, Validation Loss= 1.153, validation Accuracy= 39.800%\n",
      "Epoch 16, Average Training Loss= 1.172, Average Training Accuracy= 42.623%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.130, Accuracy= 50.000\n",
      "Iter 20, Loss= 1.162, Accuracy= 42.188\n",
      "Iter 40, Loss= 1.170, Accuracy= 39.844\n",
      "Iter 60, Loss= 1.138, Accuracy= 41.406\n",
      "\n",
      "Epoch 17, Validation Loss= 1.132, validation Accuracy= 40.700%\n",
      "Epoch 17, Average Training Loss= 1.150, Average Training Accuracy= 42.656%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.099, Accuracy= 41.406\n",
      "Iter 20, Loss= 1.116, Accuracy= 41.406\n",
      "Iter 40, Loss= 1.039, Accuracy= 46.094\n",
      "Iter 60, Loss= 1.124, Accuracy= 39.844\n",
      "\n",
      "Epoch 18, Validation Loss= 1.123, validation Accuracy= 39.600%\n",
      "Epoch 18, Average Training Loss= 1.118, Average Training Accuracy= 42.801%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.069, Accuracy= 50.000\n",
      "Iter 20, Loss= 1.131, Accuracy= 39.844\n",
      "Iter 40, Loss= 1.121, Accuracy= 39.844\n",
      "Iter 60, Loss= 1.159, Accuracy= 42.969\n",
      "\n",
      "Epoch 19, Validation Loss= 1.129, validation Accuracy= 40.800%\n",
      "Epoch 19, Average Training Loss= 1.108, Average Training Accuracy= 43.292%\n",
      "\n",
      "Iter 0, Loss= 1.119, Accuracy= 43.750\n",
      "Iter 20, Loss= 1.133, Accuracy= 37.500\n",
      "Iter 40, Loss= 1.106, Accuracy= 42.969\n",
      "Iter 60, Loss= 1.156, Accuracy= 41.406\n",
      "\n",
      "Epoch 20, Validation Loss= 1.132, validation Accuracy= 40.900%\n",
      "Epoch 20, Average Training Loss= 1.104, Average Training Accuracy= 42.623%\n",
      "\n",
      "Iter 0, Loss= 1.060, Accuracy= 45.312\n",
      "Iter 20, Loss= 1.109, Accuracy= 44.531\n",
      "Iter 40, Loss= 1.104, Accuracy= 39.062\n",
      "Iter 60, Loss= 1.081, Accuracy= 46.094\n",
      "\n",
      "Epoch 21, Validation Loss= 1.097, validation Accuracy= 40.100%\n",
      "Epoch 21, Average Training Loss= 1.087, Average Training Accuracy= 43.516%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.065, Accuracy= 44.531\n",
      "Iter 20, Loss= 1.093, Accuracy= 41.406\n",
      "Iter 40, Loss= 0.989, Accuracy= 49.219\n",
      "Iter 60, Loss= 1.100, Accuracy= 46.875\n",
      "\n",
      "Epoch 22, Validation Loss= 1.080, validation Accuracy= 42.300%\n",
      "Epoch 22, Average Training Loss= 1.090, Average Training Accuracy= 42.567%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.040, Accuracy= 47.656\n",
      "Iter 20, Loss= 1.050, Accuracy= 43.750\n",
      "Iter 40, Loss= 1.015, Accuracy= 50.000\n",
      "Iter 60, Loss= 1.019, Accuracy= 50.000\n",
      "\n",
      "Epoch 23, Validation Loss= 1.033, validation Accuracy= 45.600%\n",
      "Epoch 23, Average Training Loss= 1.054, Average Training Accuracy= 45.993%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.022, Accuracy= 46.094\n",
      "Iter 20, Loss= 0.981, Accuracy= 46.875\n",
      "Iter 40, Loss= 1.006, Accuracy= 39.062\n",
      "Iter 60, Loss= 1.011, Accuracy= 39.844\n",
      "\n",
      "Epoch 24, Validation Loss= 0.983, validation Accuracy= 46.200%\n",
      "Epoch 24, Average Training Loss= 1.000, Average Training Accuracy= 46.440%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 0.972, Accuracy= 41.406\n",
      "Iter 20, Loss= 0.912, Accuracy= 57.031\n",
      "Iter 40, Loss= 0.972, Accuracy= 50.781\n",
      "Iter 60, Loss= 1.011, Accuracy= 45.312\n",
      "\n",
      "Epoch 25, Validation Loss= 0.963, validation Accuracy= 46.900%\n",
      "Epoch 25, Average Training Loss= 0.976, Average Training Accuracy= 48.092%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 0.926, Accuracy= 51.562\n",
      "Iter 20, Loss= 0.931, Accuracy= 49.219\n",
      "Iter 40, Loss= 0.963, Accuracy= 50.000\n",
      "Iter 60, Loss= 0.991, Accuracy= 49.219\n",
      "\n",
      "Epoch 26, Validation Loss= 0.979, validation Accuracy= 45.100%\n",
      "Epoch 26, Average Training Loss= 0.978, Average Training Accuracy= 47.176%\n",
      "\n",
      "Iter 0, Loss= 0.963, Accuracy= 46.094\n",
      "Iter 20, Loss= 1.025, Accuracy= 44.531\n",
      "Iter 40, Loss= 0.968, Accuracy= 50.000\n",
      "Iter 60, Loss= 0.951, Accuracy= 46.875\n",
      "\n",
      "Epoch 27, Validation Loss= 0.951, validation Accuracy= 47.300%\n",
      "Epoch 27, Average Training Loss= 0.959, Average Training Accuracy= 47.467%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 0.951, Accuracy= 40.625\n",
      "Iter 20, Loss= 0.892, Accuracy= 52.344\n",
      "Iter 40, Loss= 0.988, Accuracy= 46.875\n",
      "Iter 60, Loss= 0.976, Accuracy= 39.844\n",
      "\n",
      "Epoch 28, Validation Loss= 0.918, validation Accuracy= 47.300%\n",
      "Epoch 28, Average Training Loss= 0.934, Average Training Accuracy= 47.076%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 0.963, Accuracy= 43.750\n",
      "Iter 20, Loss= 0.910, Accuracy= 46.094\n",
      "Iter 40, Loss= 0.927, Accuracy= 46.875\n",
      "Iter 60, Loss= 0.958, Accuracy= 46.094\n",
      "\n",
      "Epoch 29, Validation Loss= 0.927, validation Accuracy= 46.500%\n",
      "Epoch 29, Average Training Loss= 0.939, Average Training Accuracy= 47.176%\n",
      "\n",
      "Iter 0, Loss= 0.875, Accuracy= 52.344\n",
      "Iter 20, Loss= 0.876, Accuracy= 48.438\n",
      "Iter 40, Loss= 0.909, Accuracy= 53.125\n",
      "Iter 60, Loss= 0.929, Accuracy= 41.406\n",
      "\n",
      "Epoch 30, Validation Loss= 0.899, validation Accuracy= 45.400%\n",
      "Epoch 30, Average Training Loss= 0.912, Average Training Accuracy= 47.645%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 0.937, Accuracy= 38.281\n",
      "Iter 20, Loss= 0.853, Accuracy= 54.688\n",
      "Iter 40, Loss= 0.891, Accuracy= 48.438\n",
      "Iter 60, Loss= 0.879, Accuracy= 52.344\n",
      "\n",
      "Epoch 31, Validation Loss= 0.895, validation Accuracy= 48.000%\n",
      "Epoch 31, Average Training Loss= 0.901, Average Training Accuracy= 47.478%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 0.875, Accuracy= 48.438\n",
      "Iter 20, Loss= 0.877, Accuracy= 44.531\n",
      "Iter 40, Loss= 0.835, Accuracy= 50.781\n",
      "Iter 60, Loss= 0.843, Accuracy= 52.344\n",
      "\n",
      "Epoch 32, Validation Loss= 0.905, validation Accuracy= 47.200%\n",
      "Epoch 32, Average Training Loss= 0.894, Average Training Accuracy= 47.556%\n",
      "\n",
      "Iter 0, Loss= 0.845, Accuracy= 49.219\n",
      "Iter 20, Loss= 0.812, Accuracy= 52.344\n",
      "Iter 40, Loss= 0.880, Accuracy= 47.656\n",
      "Iter 60, Loss= 0.881, Accuracy= 50.781\n",
      "\n",
      "Epoch 33, Validation Loss= 0.925, validation Accuracy= 45.200%\n",
      "Epoch 33, Average Training Loss= 0.885, Average Training Accuracy= 48.348%\n",
      "\n",
      "Iter 0, Loss= 0.878, Accuracy= 48.438\n",
      "Iter 20, Loss= 0.953, Accuracy= 48.438\n",
      "Iter 40, Loss= 0.909, Accuracy= 41.406\n",
      "Iter 60, Loss= 0.969, Accuracy= 35.938\n",
      "\n",
      "Epoch 34, Validation Loss= 0.909, validation Accuracy= 44.100%\n",
      "Epoch 34, Average Training Loss= 0.896, Average Training Accuracy= 47.690%\n",
      "\n",
      "Iter 0, Loss= 0.876, Accuracy= 50.781\n",
      "Iter 20, Loss= 0.831, Accuracy= 48.438\n",
      "Iter 40, Loss= 0.884, Accuracy= 49.219\n",
      "Iter 60, Loss= 0.865, Accuracy= 51.562\n",
      "\n",
      "Epoch 35, Validation Loss= 0.902, validation Accuracy= 45.800%\n",
      "Epoch 35, Average Training Loss= 0.881, Average Training Accuracy= 48.471%\n",
      "\n",
      "Iter 0, Loss= 0.849, Accuracy= 50.781\n",
      "Iter 20, Loss= 0.909, Accuracy= 54.688\n",
      "Iter 40, Loss= 0.931, Accuracy= 48.438\n",
      "Iter 60, Loss= 0.914, Accuracy= 45.312\n",
      "\n",
      "Epoch 36, Validation Loss= 0.911, validation Accuracy= 47.300%\n",
      "Epoch 36, Average Training Loss= 0.875, Average Training Accuracy= 49.118%\n",
      "\n",
      "Iter 0, Loss= 0.854, Accuracy= 43.750\n",
      "Iter 20, Loss= 0.912, Accuracy= 50.781\n",
      "Iter 40, Loss= 0.857, Accuracy= 52.344\n",
      "Iter 60, Loss= 0.865, Accuracy= 47.656\n",
      "\n",
      "Epoch 37, Validation Loss= 0.897, validation Accuracy= 45.300%\n",
      "Epoch 37, Average Training Loss= 0.880, Average Training Accuracy= 48.203%\n",
      "\n",
      "Iter 0, Loss= 0.829, Accuracy= 50.781\n",
      "Iter 20, Loss= 0.831, Accuracy= 58.594\n",
      "Iter 40, Loss= 0.867, Accuracy= 50.000\n",
      "Iter 60, Loss= 0.828, Accuracy= 53.906\n",
      "\n",
      "Epoch 38, Validation Loss= 0.912, validation Accuracy= 45.200%\n",
      "Epoch 38, Average Training Loss= 0.868, Average Training Accuracy= 49.040%\n",
      "\n",
      "Iter 0, Loss= 0.836, Accuracy= 58.594\n",
      "Iter 20, Loss= 0.879, Accuracy= 50.000\n",
      "Iter 40, Loss= 0.869, Accuracy= 51.562\n",
      "Iter 60, Loss= 0.875, Accuracy= 48.438\n",
      "\n",
      "Epoch 39, Validation Loss= 0.929, validation Accuracy= 44.800%\n",
      "Epoch 39, Average Training Loss= 0.875, Average Training Accuracy= 48.717%\n",
      "\n",
      "Iter 0, Loss= 0.895, Accuracy= 51.562\n",
      "Iter 20, Loss= 0.857, Accuracy= 50.000\n",
      "Iter 40, Loss= 0.861, Accuracy= 45.312\n",
      "Iter 60, Loss= 0.851, Accuracy= 52.344\n",
      "\n",
      "Epoch 40, Validation Loss= 0.923, validation Accuracy= 45.400%\n",
      "Epoch 40, Average Training Loss= 0.864, Average Training Accuracy= 49.777%\n",
      "\n",
      "Iter 0, Loss= 0.837, Accuracy= 55.469\n",
      "Iter 20, Loss= 0.837, Accuracy= 50.781\n",
      "Iter 40, Loss= 0.857, Accuracy= 46.094\n",
      "Iter 60, Loss= 0.882, Accuracy= 51.562\n",
      "\n",
      "Epoch 41, Validation Loss= 0.937, validation Accuracy= 45.800%\n",
      "Epoch 41, Average Training Loss= 0.862, Average Training Accuracy= 48.906%\n",
      "\n",
      "Iter 0, Loss= 0.832, Accuracy= 46.875\n",
      "Iter 20, Loss= 0.847, Accuracy= 54.688\n",
      "Iter 40, Loss= 0.877, Accuracy= 45.312\n",
      "Iter 60, Loss= 0.818, Accuracy= 51.562\n",
      "\n",
      "Epoch 42, Validation Loss= 0.921, validation Accuracy= 45.000%\n",
      "Epoch 42, Average Training Loss= 0.863, Average Training Accuracy= 49.531%\n",
      "\n",
      "Iter 0, Loss= 0.865, Accuracy= 46.875\n",
      "Iter 20, Loss= 0.868, Accuracy= 53.125\n",
      "Iter 40, Loss= 0.795, Accuracy= 51.562\n",
      "Iter 60, Loss= 0.906, Accuracy= 48.438\n",
      "\n",
      "Epoch 43, Validation Loss= 0.948, validation Accuracy= 47.300%\n",
      "Epoch 43, Average Training Loss= 0.849, Average Training Accuracy= 51.217%\n",
      "\n",
      "Iter 0, Loss= 0.822, Accuracy= 50.000\n",
      "Iter 20, Loss= 0.863, Accuracy= 42.969\n",
      "Iter 40, Loss= 0.830, Accuracy= 49.219\n",
      "Iter 60, Loss= 0.806, Accuracy= 51.562\n",
      "\n",
      "Epoch 44, Validation Loss= 0.958, validation Accuracy= 44.000%\n",
      "Epoch 44, Average Training Loss= 0.850, Average Training Accuracy= 50.658%\n",
      "\n",
      "Iter 0, Loss= 0.878, Accuracy= 48.438\n",
      "Iter 20, Loss= 0.901, Accuracy= 50.781\n",
      "Iter 40, Loss= 0.854, Accuracy= 51.562\n",
      "Iter 60, Loss= 0.866, Accuracy= 49.219\n",
      "\n",
      "Epoch 45, Validation Loss= 0.951, validation Accuracy= 46.200%\n",
      "Epoch 45, Average Training Loss= 0.853, Average Training Accuracy= 50.513%\n",
      "\n",
      "Iter 0, Loss= 0.778, Accuracy= 55.469\n",
      "Iter 20, Loss= 0.852, Accuracy= 46.875\n",
      "Iter 40, Loss= 0.796, Accuracy= 56.250\n",
      "Iter 60, Loss= 0.831, Accuracy= 50.000\n",
      "\n",
      "Epoch 46, Validation Loss= 0.940, validation Accuracy= 46.200%\n",
      "Epoch 46, Average Training Loss= 0.845, Average Training Accuracy= 50.525%\n",
      "\n",
      "Iter 0, Loss= 0.891, Accuracy= 44.531\n",
      "Iter 20, Loss= 0.810, Accuracy= 50.000\n",
      "Iter 40, Loss= 0.845, Accuracy= 51.562\n",
      "Iter 60, Loss= 0.829, Accuracy= 53.906\n",
      "\n",
      "Epoch 47, Validation Loss= 0.949, validation Accuracy= 48.900%\n",
      "Epoch 47, Average Training Loss= 0.845, Average Training Accuracy= 50.547%\n",
      "\n",
      "Iter 0, Loss= 0.836, Accuracy= 55.469\n",
      "Iter 20, Loss= 0.840, Accuracy= 50.000\n",
      "Iter 40, Loss= 0.840, Accuracy= 55.469\n",
      "Iter 60, Loss= 0.826, Accuracy= 50.781\n",
      "\n",
      "Epoch 48, Validation Loss= 0.965, validation Accuracy= 45.800%\n",
      "Epoch 48, Average Training Loss= 0.841, Average Training Accuracy= 52.188%\n",
      "\n",
      "Iter 0, Loss= 0.806, Accuracy= 56.250\n",
      "Iter 20, Loss= 0.748, Accuracy= 61.719\n",
      "Iter 40, Loss= 0.863, Accuracy= 55.469\n",
      "Iter 60, Loss= 0.804, Accuracy= 49.219\n",
      "\n",
      "Epoch 49, Validation Loss= 0.976, validation Accuracy= 46.100%\n",
      "Epoch 49, Average Training Loss= 0.829, Average Training Accuracy= 52.790%\n",
      "\n",
      "Iter 0, Loss= 0.857, Accuracy= 49.219\n",
      "Iter 20, Loss= 0.862, Accuracy= 51.562\n",
      "Iter 40, Loss= 0.877, Accuracy= 49.219\n",
      "Iter 60, Loss= 0.824, Accuracy= 53.906\n",
      "\n",
      "Epoch 50, Validation Loss= 1.004, validation Accuracy= 48.200%\n",
      "Epoch 50, Average Training Loss= 0.830, Average Training Accuracy= 52.321%\n",
      "\n",
      "Iter 0, Loss= 0.844, Accuracy= 53.125\n",
      "Iter 20, Loss= 0.793, Accuracy= 55.469\n",
      "Iter 40, Loss= 0.814, Accuracy= 57.812\n",
      "Iter 60, Loss= 0.823, Accuracy= 56.250\n",
      "\n",
      "Epoch 51, Validation Loss= 0.963, validation Accuracy= 45.000%\n",
      "Epoch 51, Average Training Loss= 0.827, Average Training Accuracy= 53.047%\n",
      "\n",
      "Iter 0, Loss= 0.740, Accuracy= 57.031\n",
      "Iter 20, Loss= 0.815, Accuracy= 53.125\n",
      "Iter 40, Loss= 0.803, Accuracy= 50.000\n",
      "Iter 60, Loss= 0.789, Accuracy= 48.438\n",
      "\n",
      "Epoch 52, Validation Loss= 1.011, validation Accuracy= 47.500%\n",
      "Epoch 52, Average Training Loss= 0.814, Average Training Accuracy= 53.694%\n",
      "\n",
      "Early Stopping since best validation loss not decreasing for 20 epochs.\n",
      "\n",
      "Optimization Finished!\n",
      "\n",
      "Best Validation Loss: 0.895\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: # Start Tensorflow Session\n",
    "    \n",
    "    saver = tf.train.Saver() \n",
    "\n",
    "    sess.run(init) #initialize all variables\n",
    "    step = 1   \n",
    "    loss_list=[]\n",
    "    acc_list=[]\n",
    "    val_loss_list=[]\n",
    "    val_acc_list=[]\n",
    "    best_val_loss=2**30\n",
    "    prev_val_acc=0\n",
    "    patience = 20\n",
    "    impatience = 0\n",
    "    display_step = 20\n",
    "            \n",
    "    batch_size = 128\n",
    "    \n",
    "    while step <= epochs:\n",
    "        \n",
    "        total_loss=0\n",
    "        total_acc=0\n",
    "        total_val_loss = 0\n",
    "        total_val_acc = 0\n",
    "\n",
    "        batches_train_fact_stories,batches_train_questions,batches_train_answers = create_batches(train_fact_stories,train_questions,train_answers,batch_size)\n",
    "        \n",
    "        for i in xrange(len(batches_train_questions)):\n",
    "            \n",
    "            # Run optimization operation (backpropagation)\n",
    "            _,loss,acc,pred = sess.run([optimizer,cost,accuracy,prediction],\n",
    "                                       feed_dict={tf_facts: batches_train_fact_stories[i], \n",
    "                                                  tf_questions: batches_train_questions[i], \n",
    "                                                  tf_answers: batches_train_answers[i],\n",
    "                                                  keep_prob: 0.9})\n",
    "        \n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "                \n",
    "            if i%display_step == 0:\n",
    "                print \"Iter \"+str(i)+\", Loss= \"+\\\n",
    "                      \"{:.3f}\".format(loss)+\", Accuracy= \"+\\\n",
    "                      \"{:.3f}\".format(acc*100)\n",
    "                        \n",
    "        avg_loss = total_loss/len(batches_train_questions) \n",
    "        avg_acc = total_acc/len(batches_train_questions)  \n",
    "        \n",
    "        loss_list.append(avg_loss) \n",
    "        acc_list.append(avg_acc) \n",
    "\n",
    "        val_batch_size = 100 #(should be able to divide total no. of validation samples without remainder)\n",
    "        batches_val_fact_stories,batches_val_questions,batches_val_answers = create_batches(val_fact_stories,val_questions,val_answers,val_batch_size)\n",
    "        \n",
    "        for i in xrange(len(batches_val_questions)):\n",
    "            val_loss, val_acc = sess.run([cost, accuracy], \n",
    "                                         feed_dict={tf_facts: batches_val_fact_stories[i], \n",
    "                                                    tf_questions: batches_val_questions[i], \n",
    "                                                    tf_answers: batches_val_answers[i],\n",
    "                                                    keep_prob: 1})\n",
    "            total_val_loss += val_loss\n",
    "            total_val_acc += val_acc\n",
    "                      \n",
    "            \n",
    "        avg_val_loss = total_val_loss/len(batches_val_questions) \n",
    "        avg_val_acc = total_val_acc/len(batches_val_questions) \n",
    "             \n",
    "        val_loss_list.append(avg_val_loss) \n",
    "        val_acc_list.append(avg_val_acc) \n",
    "    \n",
    "\n",
    "        print \"\\nEpoch \" + str(step) + \", Validation Loss= \" + \\\n",
    "                \"{:.3f}\".format(avg_val_loss) + \", validation Accuracy= \" + \\\n",
    "                \"{:.3f}%\".format(avg_val_acc*100)+\"\"\n",
    "        print \"Epoch \" + str(step) + \", Average Training Loss= \" + \\\n",
    "              \"{:.3f}\".format(avg_loss) + \", Average Training Accuracy= \" + \\\n",
    "              \"{:.3f}%\".format(avg_acc*100)+\"\"\n",
    "        \n",
    "        impatience += 1\n",
    "            \n",
    "        if avg_val_loss <= best_val_loss: \n",
    "            impatience = 0\n",
    "            best_val_loss = avg_val_loss\n",
    "            saver.save(sess, 'DMN_Model_Backup/model.ckpt') \n",
    "            print \"Checkpoint created!\"  \n",
    "        \n",
    "        if impatience > patience:\n",
    "            print \"\\nEarly Stopping since best validation loss not decreasing for \"+str(patience)+\" epochs.\"\n",
    "            break\n",
    "            \n",
    "        print \"\"\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "    \n",
    "        \n",
    "    print \"\\nOptimization Finished!\\n\"\n",
    "    \n",
    "    print \"Best Validation Loss: %.3f\"%((best_val_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving logs about change of training and validation loss and accuracy over epochs in another file.\n",
    "\n",
    "import h5py\n",
    "\n",
    "file = h5py.File('Training_logs_DMN_plus.h5','w')\n",
    "file.create_dataset('val_acc', data=np.array(val_acc_list))\n",
    "file.create_dataset('val_loss', data=np.array(val_loss_list))\n",
    "file.create_dataset('acc', data=np.array(acc_list))\n",
    "file.create_dataset('loss', data=np.array(loss_list))\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEPCAYAAACukxSbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOjHXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f49408d3e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEPCAYAAAC5sYRSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngdUEUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4940083f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "log = h5py.File('Training_logs_DMN_plus.h5','r+') # Loading logs about change of training and validation loss and accuracy over epochs\n",
    "\n",
    "y1 = log['val_acc'][...]\n",
    "y2 = log['acc'][...]\n",
    "\n",
    "x = np.arange(1,len(y1)+1,1) # (1 = starting epoch, len(y1) = no. of epochs, 1 = step) \n",
    "\n",
    "plt.plot(x,y1,'b',label='Validation Accuracy') \n",
    "plt.plot(x,y2,'r',label='Training Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "y1 = log['val_loss'][...]\n",
    "y2 = log['loss'][...]\n",
    "\n",
    "plt.plot(x,y1,'b',label='Validation Loss')\n",
    "plt.plot(x,y2,'r',label='Training Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained weights for the model...\n",
      "INFO:tensorflow:Restoring parameters from DMN_Model_Backup/model.ckpt\n",
      "\n",
      "RESTORATION COMPLETE\n",
      "\n",
      "Testing Model Performance...\n",
      "\n",
      "Test Loss= 0.878, Test Accuracy= 50.700%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: # Begin session\n",
    "    \n",
    "    print 'Loading pre-trained weights for the model...'\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, 'DMN_Model_Backup/model.ckpt')\n",
    "    sess.run(tf.global_variables())\n",
    "    print '\\nRESTORATION COMPLETE\\n'\n",
    "    \n",
    "    print 'Testing Model Performance...'\n",
    "    \n",
    "    total_test_loss = 0\n",
    "    total_test_acc = 0\n",
    "    \n",
    "    test_batch_size = 100 #(should be able to divide total no. of test samples without remainder)\n",
    "    batches_test_fact_stories,batches_test_questions,batches_test_answers = create_batches(test_fact_stories,test_questions,test_answers,test_batch_size)\n",
    "        \n",
    "    for i in xrange(len(batches_test_questions)):\n",
    "        test_loss, test_acc = sess.run([cost, accuracy], \n",
    "                                        feed_dict={tf_facts: batches_test_fact_stories[i], \n",
    "                                                   tf_questions: batches_test_questions[i], \n",
    "                                                   tf_answers: batches_test_answers[i],\n",
    "                                                   keep_prob: 1})\n",
    "        total_test_loss += test_loss\n",
    "        total_test_acc += test_acc\n",
    "                      \n",
    "            \n",
    "    avg_test_loss = total_test_loss/len(batches_test_questions) \n",
    "    avg_test_acc = total_test_acc/len(batches_test_questions) \n",
    "\n",
    "\n",
    "    print \"\\nTest Loss= \" + \\\n",
    "          \"{:.3f}\".format(avg_test_loss) + \", Test Accuracy= \" + \\\n",
    "          \"{:.3f}%\".format(avg_test_acc*100)+\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
