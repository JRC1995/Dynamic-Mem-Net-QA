{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING PREPROCESSED DATA\n",
    "\n",
    "Loading GloVe word embeddings. Building functions to convert words into their vector representations and vice versa. Loading babi induction task 10K dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded!\n",
      "(10000, 9, 6, 100)\n",
      "(10000, 5, 100)\n",
      "(10000,)\n",
      "(1000, 9, 6, 100)\n",
      "(1000, 5, 100)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from __future__ import division\n",
    "\n",
    "filename = 'glove.6B.100d.txt'\n",
    "\n",
    "def loadEmbeddings(filename):\n",
    "    vocab = []\n",
    "    embd = []\n",
    "    file = open(filename,'r')\n",
    "    for line in file.readlines():\n",
    "        row = line.strip().split(' ')\n",
    "        vocab.append(row[0])\n",
    "        embd.append(row[1:])\n",
    "    print('Loaded!')\n",
    "    file.close()\n",
    "    return vocab,embd\n",
    "vocab,embd = loadEmbeddings(filename)\n",
    "\n",
    "\n",
    "word_vec_dim = len(embd[0])\n",
    "\n",
    "vocab.append('<UNK>')\n",
    "embd.append(np.asarray(embd[vocab.index('unk')],np.float32)+0.01)\n",
    "\n",
    "vocab.append('<EOS>')\n",
    "embd.append(np.asarray(embd[vocab.index('eos')],np.float32)+0.01)\n",
    "\n",
    "vocab.append('<PAD>')\n",
    "embd.append(np.zeros((word_vec_dim),np.float32))\n",
    "\n",
    "embedding = np.asarray(embd)\n",
    "embedding = embedding.astype(np.float32)\n",
    "\n",
    "def word2vec(word):  # converts a given word into its vector representation\n",
    "    if word in vocab:\n",
    "        return embedding[vocab.index(word)]\n",
    "    else:\n",
    "        return embedding[vocab.index('<UNK>')]\n",
    "\n",
    "def most_similar_eucli(x):\n",
    "    xminusy = np.subtract(embedding,x)\n",
    "    sq_xminusy = np.square(xminusy)\n",
    "    sum_sq_xminusy = np.sum(sq_xminusy,1)\n",
    "    eucli_dists = np.sqrt(sum_sq_xminusy)\n",
    "    return np.argsort(eucli_dists)\n",
    "\n",
    "def vec2word(vec):   # converts a given vector representation into the represented word \n",
    "    most_similars = most_similar_eucli(np.asarray(vec,np.float32))\n",
    "    return vocab[most_similars[0]]\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open ('embeddingPICKLE', 'rb') as fp:\n",
    "    processed_data = pickle.load(fp)\n",
    "\n",
    "fact_stories = processed_data[0]\n",
    "questions = processed_data[1]\n",
    "answers = np.reshape(processed_data[2],(len(processed_data[2])))\n",
    "test_fact_stories = processed_data[3]\n",
    "test_questions = processed_data[4]\n",
    "test_answers = np.reshape(processed_data[5],(len(processed_data[5])))\n",
    "\n",
    "print fact_stories.shape\n",
    "print questions.shape\n",
    "print answers.shape\n",
    "print test_fact_stories.shape\n",
    "print test_questions.shape\n",
    "print test_answers.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING TRAINING AND VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "train_fact_stories = []\n",
    "train_questions = []\n",
    "train_answers = []\n",
    "val_fact_stories = []\n",
    "val_questions = []\n",
    "val_answers = []\n",
    "\n",
    "p=90 #(90% data used for training. Rest for validation)\n",
    "    \n",
    "train_len = int((p/100)*len(fact_stories))\n",
    "val_len = int(((100-p)/100)*len(fact_stories))\n",
    "\n",
    "train_fact_stories = fact_stories[0:train_len] \n",
    "val_fact_stories = fact_stories[train_len:(train_len+val_len)]\n",
    "\n",
    "train_questions = questions[0:train_len] \n",
    "val_questions = questions[train_len:(train_len+val_len)] \n",
    "\n",
    "train_answers = answers[0:train_len] \n",
    "val_answers = answers[train_len:(train_len+val_len)] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SENTENCE READING LAYER IMPLEMENTED BEFOREHAND \n",
    "\n",
    "Positionally encode the word vectors in each sentence, and combine all the words in the sentence to create a fixed sized vector representation for the sentence.\n",
    "\n",
    "\"sentence embedding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_reader(fact_stories): #positional_encoder\n",
    "    \n",
    "    pe_fact_stories = np.zeros((fact_stories.shape[0],fact_stories.shape[1],word_vec_dim),np.float32)\n",
    "    \n",
    "    for fact_story_index in xrange(0,len(fact_stories)):\n",
    "        for fact_index in xrange(0,len(fact_stories[fact_story_index])):\n",
    "            \n",
    "            M = len(fact_stories[fact_story_index,fact_index]) #length of sentence (fact)\n",
    "            l = np.zeros((word_vec_dim),np.float32) \n",
    "            \n",
    "            # ljd = (1 − j/M) − (d/D)(1 − 2j/M),\n",
    "            \n",
    "            for word_position in xrange(0,M):\n",
    "                for dimension in xrange(word_vec_dim):\n",
    "                    \n",
    "                    j = word_position + 1 # making position start from 1 instead of 0\n",
    "                    d = dimension + 1 #making dimensions start from 1 isntead of 0 (1-50 instead of 0-49)\n",
    "                    \n",
    "                    l[dimension] = (1-(j/M)) - (d/word_vec_dim)*(1-2*(j/M))\n",
    "                \n",
    "                fact_stories[fact_story_index,fact_index,word_position] = np.multiply(l,fact_stories[fact_story_index,fact_index,word_position])\n",
    "\n",
    "            pe_fact_stories[fact_story_index,fact_index] = np.sum(fact_stories[fact_story_index,fact_index],0)\n",
    "\n",
    "    return pe_fact_stories\n",
    "\n",
    "train_fact_stories = sentence_reader(train_fact_stories)\n",
    "val_fact_stories = sentence_reader(val_fact_stories)\n",
    "test_fact_stories = sentence_reader(test_fact_stories)\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 9, 100)\n",
      "(1000, 9, 100)\n",
      "(1000, 9, 100)\n"
     ]
    }
   ],
   "source": [
    "print train_fact_stories.shape\n",
    "print val_fact_stories.shape\n",
    "print test_fact_stories.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create randomized batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(fact_stories,questions,answers,batch_size):\n",
    "    \n",
    "    shuffle = np.arange(len(questions))\n",
    "    np.random.shuffle(shuffle)\n",
    "    \n",
    "    batches_fact_stories = []\n",
    "    batches_questions = []\n",
    "    batches_answers = []\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    while i+batch_size<=len(questions):\n",
    "        batch_fact_stories = []\n",
    "        batch_questions = []\n",
    "        batch_answers = []\n",
    "        \n",
    "        for j in xrange(i,i+batch_size):\n",
    "            batch_fact_stories.append(fact_stories[shuffle[j]])\n",
    "            batch_questions.append(questions[shuffle[j]])\n",
    "            batch_answers.append(answers[shuffle[j]])\n",
    "            \n",
    "        batch_fact_stories = np.asarray(batch_fact_stories,np.float32)\n",
    "        batch_fact_stories = np.transpose(batch_fact_stories,[1,0,2])\n",
    "        #result = number of facts x batch_size x fact sentence size x word vector size\n",
    "        \n",
    "        batch_questions = np.asarray(batch_questions,np.float32)\n",
    "        batch_questions = np.transpose(batch_questions,[1,0,2])\n",
    "        #result = question_length x batch_size x fact sentence size x word vector size\n",
    "        \n",
    "        batches_fact_stories.append(batch_fact_stories)\n",
    "        batches_questions.append(batch_questions)\n",
    "        batches_answers.append(batch_answers)\n",
    "        \n",
    "        i+=batch_size\n",
    "        \n",
    "    batches_fact_stories = np.asarray(batches_fact_stories,np.float32)\n",
    "    batches_questions = np.asarray(batches_questions,np.float32)\n",
    "    batches_answers = np.asarray(batches_answers,np.float32)\n",
    "    \n",
    "    return batches_fact_stories,batches_questions,batches_answers\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Tensorflow placeholders\n",
    "\n",
    "tf_facts = tf.placeholder(tf.float32, [None,None,word_vec_dim])\n",
    "tf_questions = tf.placeholder(tf.float32, [None,None,word_vec_dim])\n",
    "tf_answers = tf.placeholder(tf.int32,[None])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#hyperparameters\n",
    "epochs = 256\n",
    "learning_rate = 0.001\n",
    "hidden_size = 100\n",
    "passes = 3\n",
    "beta = 0.0001 #l2 regularization scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low level api implementation of GRU\n",
    "\n",
    "Returns a tensor of all the hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU(inp,hidden,\n",
    "        wz,uz,bz,\n",
    "        wr,ur,br,\n",
    "        w,u,b,\n",
    "        seq_len):\n",
    "\n",
    "    hidden_lists = tf.TensorArray(size=seq_len,dtype=tf.float32)\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    def cond(i,hidden,hidden_lists):\n",
    "        return i < seq_len\n",
    "    \n",
    "    def body(i,hidden,hidden_lists):\n",
    "        \n",
    "        x = inp[i]\n",
    "\n",
    "        # GRU EQUATIONS:\n",
    "        z = tf.sigmoid( tf.matmul(x,wz) + tf.matmul(hidden,uz) + bz)\n",
    "        r = tf.sigmoid( tf.matmul(x,wr) + tf.matmul(hidden,ur) + br)\n",
    "        h_ = tf.tanh( tf.matmul(x,w) + tf.multiply(r,tf.matmul(hidden,u)) + b)\n",
    "        hidden = tf.multiply(z,hidden) + tf.multiply((1-z),h_)\n",
    "\n",
    "        hidden_lists = hidden_lists.write(i,hidden)\n",
    "        \n",
    "        return i+1,hidden,hidden_lists\n",
    "    \n",
    "    _,_,hidden_lists = tf.while_loop(cond,body,[i,hidden,hidden_lists])\n",
    "    \n",
    "    return hidden_lists.stack()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention based GRU as used in DMN+ model\n",
    "\n",
    "Returns only the final hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_based_GRU(inp,hidden,\n",
    "                        wr,ur,br,\n",
    "                        w,u,b,\n",
    "                        g,seq_len):\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    def cond(i,hidden):\n",
    "        return i < seq_len\n",
    "    \n",
    "    def body(i,hidden):\n",
    "        \n",
    "        x = inp[i]\n",
    "\n",
    "        # GRU EQUATIONS:\n",
    "        r = tf.sigmoid( tf.matmul(x,wr) + tf.matmul(hidden,ur) + br)\n",
    "        h_ = tf.tanh( tf.matmul(x,w) + tf.multiply(r,tf.matmul(hidden,u)) + b)\n",
    "        hidden = tf.multiply(g[i],hidden) + tf.multiply((1-g[i]),h_)\n",
    "        \n",
    "        return i+1,hidden\n",
    "    \n",
    "    _,hidden = tf.while_loop(cond,body,[i,hidden])\n",
    "    \n",
    "    return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the trainable parameters initialized here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "\n",
    "# FORWARD GRU PARAMETERS FOR INPUT MODULE\n",
    "\n",
    "wzf = tf.get_variable(\"wzf\", shape=[word_vec_dim, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "uzf = tf.get_variable(\"uzf\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "bzf = tf.Variable(tf.random_uniform(shape=[hidden_size],dtype=tf.float32))\n",
    "\n",
    "wrf = tf.get_variable(\"wrf\", shape=[word_vec_dim, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "urf = tf.get_variable(\"urf\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "brf = tf.Variable(tf.random_uniform(shape=[hidden_size],dtype=tf.float32))\n",
    "\n",
    "wf = tf.get_variable(\"wf\", shape=[word_vec_dim, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "uf = tf.get_variable(\"uf\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "bf = tf.Variable(tf.random_uniform(shape=[hidden_size],dtype=tf.float32))\n",
    "\n",
    "# BACKWARD GRU PARAMETERS FOR INPUT MODULE\n",
    "\n",
    "wzb = tf.get_variable(\"wzb\", shape=[word_vec_dim, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "uzb = tf.get_variable(\"uzb\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "bzb = tf.Variable(tf.random_uniform(shape=[hidden_size],dtype=tf.float32))\n",
    "\n",
    "wrb = tf.get_variable(\"wrb\", shape=[word_vec_dim, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "urb = tf.get_variable(\"urb\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "brb = tf.Variable(tf.random_uniform(shape=[hidden_size],dtype=tf.float32))\n",
    "\n",
    "wb = tf.get_variable(\"wb\", shape=[word_vec_dim, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "ub = tf.get_variable(\"ub\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "bb = tf.Variable(tf.random_uniform(shape=[hidden_size],dtype=tf.float32))\n",
    "\n",
    "# GRU PARAMETERS FOR QUESTION MODULE (TO ENCODE THE QUESTIONS)\n",
    "\n",
    "wzq = tf.get_variable(\"wzq\", shape=[word_vec_dim, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "uzq = tf.get_variable(\"uzq\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "bzq = tf.Variable(tf.random_uniform(shape=[hidden_size],dtype=tf.float32))\n",
    "\n",
    "wrq = tf.get_variable(\"wrq\", shape=[word_vec_dim, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "urq = tf.get_variable(\"urq\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "brq = tf.Variable(tf.random_uniform(shape=[hidden_size],dtype=tf.float32))\n",
    "\n",
    "wq = tf.get_variable(\"wq\", shape=[word_vec_dim, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "uq = tf.get_variable(\"uq\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "bq = tf.Variable(tf.random_uniform(shape=[hidden_size],dtype=tf.float32))\n",
    "\n",
    "\n",
    "# EPISODIC MEMORY\n",
    "\n",
    "inter_neurons = 2048\n",
    "w1 = tf.get_variable(\"w1\", shape=[hidden_size*4, inter_neurons],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_uniform(shape=[inter_neurons],dtype=tf.float32))\n",
    "w2 = tf.get_variable(\"w2\", shape=[inter_neurons,1],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_uniform(shape=[1],dtype=tf.float32))\n",
    "\n",
    "# ATTENTION BASED GRU PARAMETERS\n",
    "\n",
    "wratt = tf.get_variable(\"wratt\", shape=[hidden_size,hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "uratt = tf.get_variable(\"uratt\", shape=[hidden_size,hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "bratt = tf.Variable(tf.random_uniform(shape=[hidden_size],dtype=tf.float32))\n",
    "\n",
    "watt = tf.get_variable(\"watt\", shape=[hidden_size,hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "uatt = tf.get_variable(\"uatt\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "batt = tf.Variable(tf.random_uniform(shape=[hidden_size],dtype=tf.float32))\n",
    "\n",
    "# MEMORY UPDATE PARAMETERS\n",
    "\n",
    "wt = tf.get_variable(\"wt\", shape=[passes,hidden_size*3,hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "bt = tf.Variable(tf.random_uniform(shape=[passes,hidden_size],dtype=tf.float32))\n",
    "\n",
    "# Answer module\n",
    "\n",
    "# GRU PARAMETERS FOR QUESTION MODULE (TO ENCODE THE QUESTIONS)\n",
    "\n",
    "wza = tf.get_variable(\"wza\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "uza = tf.get_variable(\"uza\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "bza = tf.Variable(tf.random_uniform(shape=[hidden_size],dtype=tf.float32))\n",
    "\n",
    "wra = tf.get_variable(\"wra\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "ura = tf.get_variable(\"ura\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "bra = tf.Variable(tf.random_uniform(shape=[hidden_size],dtype=tf.float32))\n",
    "\n",
    "wa = tf.get_variable(\"wa\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "ua = tf.get_variable(\"ua\", shape=[hidden_size, hidden_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "ba = tf.Variable(tf.random_uniform(shape=[hidden_size],dtype=tf.float32))\n",
    "\n",
    "    \n",
    "wa1 = tf.get_variable(\"wa1\", shape=[hidden_size,len(vocab)],initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "all_weights = [wzf,uzf,wrf,urf,wf,uf,wzb,uzb,wrb,urb,wb,ub,\n",
    "               wzq,uzq,wrq,urq,wq,uq,wq,uq,wratt,uratt,watt,uatt,\n",
    "               wza,uza,wra,ura,wa,ua,w1,w2,wt,wa1]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Memory Network + Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DMN(tf_facts,tf_questions):\n",
    "    \n",
    "    facts_num = tf.shape(tf_facts)[0]\n",
    "    tf_batch_size = tf.shape(tf_questions)[1]\n",
    "    question_len = tf.shape(tf_questions)[0]\n",
    "    \n",
    "    hidden = tf.zeros([tf_batch_size,hidden_size],tf.float32)\n",
    "\n",
    "    \n",
    "    tf_facts = tf.nn.dropout(tf_facts,keep_prob)\n",
    "    \n",
    "    # Input Module\n",
    "    # input fusion layer \n",
    "    # bidirectional GRU\n",
    "    \n",
    "    forward = GRU(tf_facts,hidden,\n",
    "                  wzf,uzf,bzf,\n",
    "                  wrf,urf,brf,\n",
    "                  wf,uf,bf,\n",
    "                  facts_num)\n",
    "    \n",
    "    backward = GRU(tf.reverse(tf_facts,[0]),hidden,\n",
    "                   wzf,uzf,bzf,\n",
    "                   wrf,urf,brf,\n",
    "                   wf,uf,bf,\n",
    "                   facts_num)\n",
    "    \n",
    "    encoded_input = forward + backward\n",
    "\n",
    "    # Question Module\n",
    "    \n",
    "    question_representation = GRU(tf_questions,hidden,\n",
    "                                  wzq,uzq,bzq,\n",
    "                                  wrq,urq,brq,\n",
    "                                  wq,uq,bq,\n",
    "                                  question_len)\n",
    "    \n",
    "    question_representation = question_representation[question_len-1]\n",
    "\n",
    "    question_representation = tf.reshape(question_representation,[tf_batch_size,1,hidden_size])\n",
    "    \n",
    "    \n",
    "    # Episodci Memory Module\n",
    "    \n",
    "    episodic_memory = question_representation\n",
    "    \n",
    "    encoded_input = tf.transpose(encoded_input,[1,0,2])\n",
    "    #now shape = batch_size x facts_num x hidden_size\n",
    "    \n",
    "    \n",
    "    i=0\n",
    "\n",
    "    def cond(i,episodic_memory):\n",
    "        return i < passes\n",
    "    \n",
    "    def body(i,episodic_memory):\n",
    "        \n",
    "        # Attention Mechanism\n",
    "        \n",
    "        Z1 = tf.multiply(encoded_input,question_representation)\n",
    "        Z2 = tf.multiply(encoded_input,episodic_memory)\n",
    "        Z3 = tf.abs(tf.subtract(encoded_input,question_representation))\n",
    "        Z4 = tf.abs(tf.subtract(encoded_input,episodic_memory))\n",
    "        \n",
    "        Z = tf.concat([Z1,Z2,Z3,Z4],2)\n",
    "        \n",
    "        Z = tf.reshape(Z,[-1,4*hidden_size])\n",
    "        Z = tf.add( tf.matmul( tf.tanh( tf.add( tf.matmul(Z,w1),b1 ) ),w2 ) , b2)\n",
    "        Z = tf.reshape(Z,[tf_batch_size,facts_num])\n",
    "        \n",
    "        g = tf.nn.softmax(Z)\n",
    "        g = tf.reshape(g,[tf_batch_size,facts_num])\n",
    "        g = tf.transpose(g,[1,0])\n",
    "        g = tf.reshape(g,[facts_num,tf_batch_size,1])\n",
    "        \n",
    "        context_vector = attention_based_GRU(tf.transpose(encoded_input,[1,0,2]),\n",
    "                                             tf.reshape(episodic_memory,[tf_batch_size,hidden_size]),\n",
    "                                             wratt,uratt,bratt,\n",
    "                                             watt,uatt,batt,\n",
    "                                             g,facts_num)\n",
    "        \n",
    "        context_vector = tf.reshape(context_vector,[tf_batch_size,1,hidden_size])\n",
    "        \n",
    "        # Episodic Memory Update\n",
    "        \n",
    "        concated = tf.concat([episodic_memory,context_vector,question_representation],2)\n",
    "        concated = tf.reshape(concated,[-1,3*hidden_size])\n",
    "        \n",
    "        episodic_memory = tf.nn.relu(tf.matmul(concated,wt[i]) + bt[i])\n",
    "        \n",
    "        episodic_memory = tf.reshape(episodic_memory,[tf_batch_size,1,hidden_size])\n",
    "\n",
    "        return i+1,episodic_memory\n",
    "    \n",
    "    \n",
    "    _,episodic_memory = tf.while_loop(cond,body,[i,episodic_memory]) \n",
    "    \n",
    "    # Answer module\n",
    "    \n",
    "    episodic_memory = tf.reshape(episodic_memory,[tf_batch_size,hidden_size])\n",
    "    episodic_memory = tf.nn.dropout(episodic_memory,keep_prob)\n",
    "    \n",
    "    # sending in only the question as input. \n",
    "    # Only focusing on single word prediction, so no need of taking previous y into context. \n",
    "    # (because there will never be a previous y. No need to create <SOS> either.)\n",
    "\n",
    "    question_representation = tf.transpose(question_representation,[1,0,2])\n",
    "    question_representation = tf.nn.dropout(question_representation,keep_prob)\n",
    "   \n",
    "    y_state = GRU(question_representation,episodic_memory,\n",
    "                  wza,uza,bza,\n",
    "                  wra,ura,bra,\n",
    "                  wa,ua,ba,1)\n",
    "    \n",
    "    y_state = y_state[0]\n",
    "    y_state = tf.reshape(y_state,[tf_batch_size,hidden_size])\n",
    "    y = tf.matmul(y_state,wa1) \n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function, Evaluation, Optimization function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = DMN(tf_facts,tf_questions)\n",
    "\n",
    "\n",
    "# l2 regularization\n",
    "regularizer = 0\n",
    "for weight in all_weights:\n",
    "    regularizer += tf.nn.l2_loss(weight)\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model_output, labels=tf_answers)) + beta*regularizer\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate,centered=True).minimize(cost)\n",
    "\n",
    "#Evaluate model\n",
    "correct_pred = tf.equal(tf.cast(tf.argmax(model_output,1),tf.int32),tf_answers)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "prediction = tf.argmax(model_output,1)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss= 13.100, Accuracy= 0.000\n",
      "Iter 20, Loss= 2.027, Accuracy= 25.000\n",
      "Iter 40, Loss= 1.889, Accuracy= 29.688\n",
      "Iter 60, Loss= 1.764, Accuracy= 22.656\n",
      "\n",
      "Epoch 1, Validation Loss= 1.586, validation Accuracy= 25.500%\n",
      "Epoch 1, Average Training Loss= 3.512, Average Training Accuracy= 24.900%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.586, Accuracy= 26.562\n",
      "Iter 20, Loss= 1.511, Accuracy= 26.562\n",
      "Iter 40, Loss= 1.475, Accuracy= 25.781\n",
      "Iter 60, Loss= 1.454, Accuracy= 31.250\n",
      "\n",
      "Epoch 2, Validation Loss= 1.469, validation Accuracy= 27.000%\n",
      "Epoch 2, Average Training Loss= 1.501, Average Training Accuracy= 25.246%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.461, Accuracy= 26.562\n",
      "Iter 20, Loss= 1.501, Accuracy= 27.344\n",
      "Iter 40, Loss= 1.507, Accuracy= 23.438\n",
      "Iter 60, Loss= 1.446, Accuracy= 25.781\n",
      "\n",
      "Epoch 3, Validation Loss= 1.460, validation Accuracy= 25.100%\n",
      "Epoch 3, Average Training Loss= 1.475, Average Training Accuracy= 24.821%\n",
      "\n",
      "Iter 0, Loss= 1.468, Accuracy= 21.875\n",
      "Iter 20, Loss= 1.449, Accuracy= 21.875\n",
      "Iter 40, Loss= 1.451, Accuracy= 23.438\n",
      "Iter 60, Loss= 1.435, Accuracy= 26.562\n",
      "\n",
      "Epoch 4, Validation Loss= 1.449, validation Accuracy= 27.000%\n",
      "Epoch 4, Average Training Loss= 1.461, Average Training Accuracy= 24.833%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.444, Accuracy= 26.562\n",
      "Iter 20, Loss= 1.440, Accuracy= 32.031\n",
      "Iter 40, Loss= 1.465, Accuracy= 24.219\n",
      "Iter 60, Loss= 1.463, Accuracy= 25.781\n",
      "\n",
      "Epoch 5, Validation Loss= 1.438, validation Accuracy= 25.500%\n",
      "Epoch 5, Average Training Loss= 1.453, Average Training Accuracy= 25.022%\n",
      "\n",
      "Iter 0, Loss= 1.457, Accuracy= 23.438\n",
      "Iter 20, Loss= 1.466, Accuracy= 22.656\n",
      "Iter 40, Loss= 1.434, Accuracy= 28.125\n",
      "Iter 60, Loss= 1.432, Accuracy= 29.688\n",
      "\n",
      "Epoch 6, Validation Loss= 1.435, validation Accuracy= 27.000%\n",
      "Epoch 6, Average Training Loss= 1.446, Average Training Accuracy= 24.922%\n",
      "\n",
      "Iter 0, Loss= 1.426, Accuracy= 28.906\n",
      "Iter 20, Loss= 1.430, Accuracy= 27.344\n",
      "Iter 40, Loss= 1.456, Accuracy= 20.312\n",
      "Iter 60, Loss= 1.442, Accuracy= 21.875\n",
      "\n",
      "Epoch 7, Validation Loss= 1.426, validation Accuracy= 27.000%\n",
      "Epoch 7, Average Training Loss= 1.444, Average Training Accuracy= 24.933%\n",
      "\n",
      "Iter 0, Loss= 1.427, Accuracy= 25.000\n",
      "Iter 20, Loss= 1.442, Accuracy= 25.000\n",
      "Iter 40, Loss= 1.434, Accuracy= 24.219\n",
      "Iter 60, Loss= 1.437, Accuracy= 22.656\n",
      "\n",
      "Epoch 8, Validation Loss= 1.426, validation Accuracy= 22.400%\n",
      "Epoch 8, Average Training Loss= 1.438, Average Training Accuracy= 24.531%\n",
      "\n",
      "Iter 0, Loss= 1.420, Accuracy= 30.469\n",
      "Iter 20, Loss= 1.428, Accuracy= 21.094\n",
      "Iter 40, Loss= 1.412, Accuracy= 26.562\n",
      "Iter 60, Loss= 1.405, Accuracy= 30.469\n",
      "\n",
      "Epoch 9, Validation Loss= 1.425, validation Accuracy= 27.000%\n",
      "Epoch 9, Average Training Loss= 1.432, Average Training Accuracy= 24.833%\n",
      "\n",
      "Iter 0, Loss= 1.412, Accuracy= 28.125\n",
      "Iter 20, Loss= 1.424, Accuracy= 25.000\n",
      "Iter 40, Loss= 1.412, Accuracy= 25.781\n",
      "Iter 60, Loss= 1.456, Accuracy= 21.875\n",
      "\n",
      "Epoch 10, Validation Loss= 1.431, validation Accuracy= 25.500%\n",
      "Epoch 10, Average Training Loss= 1.430, Average Training Accuracy= 25.324%\n",
      "\n",
      "Iter 0, Loss= 1.430, Accuracy= 23.438\n",
      "Iter 20, Loss= 1.454, Accuracy= 25.781\n",
      "Iter 40, Loss= 1.397, Accuracy= 28.906\n",
      "Iter 60, Loss= 1.413, Accuracy= 24.219\n",
      "\n",
      "Epoch 11, Validation Loss= 1.413, validation Accuracy= 25.100%\n",
      "Epoch 11, Average Training Loss= 1.428, Average Training Accuracy= 25.022%\n",
      "\n",
      "Iter 0, Loss= 1.417, Accuracy= 22.656\n",
      "Iter 20, Loss= 1.422, Accuracy= 20.312\n",
      "Iter 40, Loss= 1.420, Accuracy= 24.219\n",
      "Iter 60, Loss= 1.471, Accuracy= 25.781\n",
      "\n",
      "Epoch 12, Validation Loss= 1.424, validation Accuracy= 25.100%\n",
      "Epoch 12, Average Training Loss= 1.431, Average Training Accuracy= 24.174%\n",
      "\n",
      "Iter 0, Loss= 1.446, Accuracy= 15.625\n",
      "Iter 20, Loss= 1.401, Accuracy= 29.688\n",
      "Iter 40, Loss= 1.397, Accuracy= 31.250\n",
      "Iter 60, Loss= 1.464, Accuracy= 20.312\n",
      "\n",
      "Epoch 13, Validation Loss= 1.422, validation Accuracy= 22.400%\n",
      "Epoch 13, Average Training Loss= 1.428, Average Training Accuracy= 25.301%\n",
      "\n",
      "Iter 0, Loss= 1.462, Accuracy= 17.188\n",
      "Iter 20, Loss= 1.426, Accuracy= 16.406\n",
      "Iter 40, Loss= 1.424, Accuracy= 23.438\n",
      "Iter 60, Loss= 1.424, Accuracy= 24.219\n",
      "\n",
      "Epoch 14, Validation Loss= 1.408, validation Accuracy= 25.100%\n",
      "Epoch 14, Average Training Loss= 1.415, Average Training Accuracy= 24.654%\n",
      "\n",
      "Iter 0, Loss= 1.440, Accuracy= 21.875\n",
      "Iter 20, Loss= 1.396, Accuracy= 31.250\n",
      "Iter 40, Loss= 1.399, Accuracy= 29.688\n",
      "Iter 60, Loss= 1.418, Accuracy= 25.000\n",
      "\n",
      "Epoch 15, Validation Loss= 1.423, validation Accuracy= 22.400%\n",
      "Epoch 15, Average Training Loss= 1.418, Average Training Accuracy= 24.118%\n",
      "\n",
      "Iter 0, Loss= 1.416, Accuracy= 23.438\n",
      "Iter 20, Loss= 1.440, Accuracy= 20.312\n",
      "Iter 40, Loss= 1.402, Accuracy= 30.469\n",
      "Iter 60, Loss= 1.439, Accuracy= 19.531\n",
      "\n",
      "Epoch 16, Validation Loss= 1.403, validation Accuracy= 25.500%\n",
      "Epoch 16, Average Training Loss= 1.418, Average Training Accuracy= 24.330%\n",
      "\n",
      "Iter 0, Loss= 1.392, Accuracy= 32.812\n",
      "Iter 20, Loss= 1.402, Accuracy= 25.781\n",
      "Iter 40, Loss= 1.409, Accuracy= 26.562\n",
      "Iter 60, Loss= 1.418, Accuracy= 22.656\n",
      "\n",
      "Epoch 17, Validation Loss= 1.430, validation Accuracy= 25.100%\n",
      "Epoch 17, Average Training Loss= 1.416, Average Training Accuracy= 25.279%\n",
      "\n",
      "Iter 0, Loss= 1.433, Accuracy= 24.219\n",
      "Iter 20, Loss= 1.386, Accuracy= 29.688\n",
      "Iter 40, Loss= 1.390, Accuracy= 32.812\n",
      "Iter 60, Loss= 1.422, Accuracy= 20.312\n",
      "\n",
      "Epoch 18, Validation Loss= 1.434, validation Accuracy= 22.400%\n",
      "Epoch 18, Average Training Loss= 1.418, Average Training Accuracy= 24.888%\n",
      "\n",
      "Iter 0, Loss= 1.410, Accuracy= 28.125\n",
      "Iter 20, Loss= 1.425, Accuracy= 19.531\n",
      "Iter 40, Loss= 1.398, Accuracy= 31.250\n",
      "Iter 60, Loss= 1.409, Accuracy= 22.656\n",
      "\n",
      "Epoch 19, Validation Loss= 1.416, validation Accuracy= 22.400%\n",
      "Epoch 19, Average Training Loss= 1.417, Average Training Accuracy= 25.792%\n",
      "\n",
      "Iter 0, Loss= 1.404, Accuracy= 25.000\n",
      "Iter 20, Loss= 1.464, Accuracy= 21.875\n",
      "Iter 40, Loss= 1.425, Accuracy= 22.656\n",
      "Iter 60, Loss= 1.433, Accuracy= 26.562\n",
      "\n",
      "Epoch 20, Validation Loss= 1.413, validation Accuracy= 25.100%\n",
      "Epoch 20, Average Training Loss= 1.414, Average Training Accuracy= 25.435%\n",
      "\n",
      "Iter 0, Loss= 1.407, Accuracy= 25.000\n",
      "Iter 20, Loss= 1.447, Accuracy= 26.562\n",
      "Iter 40, Loss= 1.421, Accuracy= 22.656\n",
      "Iter 60, Loss= 1.428, Accuracy= 19.531\n",
      "\n",
      "Epoch 21, Validation Loss= 1.416, validation Accuracy= 25.500%\n",
      "Epoch 21, Average Training Loss= 1.417, Average Training Accuracy= 25.033%\n",
      "\n",
      "Iter 0, Loss= 1.464, Accuracy= 18.750\n",
      "Iter 20, Loss= 1.454, Accuracy= 17.969\n",
      "Iter 40, Loss= 1.396, Accuracy= 25.781\n",
      "Iter 60, Loss= 1.412, Accuracy= 22.656\n",
      "\n",
      "Epoch 22, Validation Loss= 1.450, validation Accuracy= 22.400%\n",
      "Epoch 22, Average Training Loss= 1.410, Average Training Accuracy= 24.632%\n",
      "\n",
      "Iter 0, Loss= 1.422, Accuracy= 23.438\n",
      "Iter 20, Loss= 1.398, Accuracy= 28.906\n",
      "Iter 40, Loss= 1.424, Accuracy= 21.094\n",
      "Iter 60, Loss= 1.407, Accuracy= 25.000\n",
      "\n",
      "Epoch 23, Validation Loss= 1.405, validation Accuracy= 25.500%\n",
      "Epoch 23, Average Training Loss= 1.412, Average Training Accuracy= 25.022%\n",
      "\n",
      "Iter 0, Loss= 1.414, Accuracy= 27.344\n",
      "Iter 20, Loss= 1.423, Accuracy= 22.656\n",
      "Iter 40, Loss= 1.428, Accuracy= 30.469\n",
      "Iter 60, Loss= 1.391, Accuracy= 28.906\n",
      "\n",
      "Epoch 24, Validation Loss= 1.419, validation Accuracy= 25.100%\n",
      "Epoch 24, Average Training Loss= 1.414, Average Training Accuracy= 25.480%\n",
      "\n",
      "Iter 0, Loss= 1.411, Accuracy= 22.656\n",
      "Iter 20, Loss= 1.412, Accuracy= 26.562\n",
      "Iter 40, Loss= 1.445, Accuracy= 20.312\n",
      "Iter 60, Loss= 1.388, Accuracy= 31.250\n",
      "\n",
      "Epoch 25, Validation Loss= 1.409, validation Accuracy= 25.500%\n",
      "Epoch 25, Average Training Loss= 1.416, Average Training Accuracy= 24.877%\n",
      "\n",
      "Iter 0, Loss= 1.414, Accuracy= 28.125\n",
      "Iter 20, Loss= 1.435, Accuracy= 25.000\n",
      "Iter 40, Loss= 1.395, Accuracy= 25.781\n",
      "Iter 60, Loss= 1.433, Accuracy= 21.094\n",
      "\n",
      "Epoch 26, Validation Loss= 1.400, validation Accuracy= 25.100%\n",
      "Epoch 26, Average Training Loss= 1.412, Average Training Accuracy= 24.275%\n",
      "\n",
      "Iter 0, Loss= 1.383, Accuracy= 33.594\n",
      "Iter 20, Loss= 1.443, Accuracy= 24.219\n",
      "Iter 40, Loss= 1.390, Accuracy= 20.312\n",
      "Iter 60, Loss= 1.395, Accuracy= 21.875\n",
      "\n",
      "Epoch 27, Validation Loss= 1.401, validation Accuracy= 27.000%\n",
      "Epoch 27, Average Training Loss= 1.406, Average Training Accuracy= 25.089%\n",
      "\n",
      "Iter 0, Loss= 1.416, Accuracy= 18.750\n",
      "Iter 20, Loss= 1.416, Accuracy= 26.562\n",
      "Iter 40, Loss= 1.387, Accuracy= 26.562\n",
      "Iter 60, Loss= 1.407, Accuracy= 25.000\n",
      "\n",
      "Epoch 28, Validation Loss= 1.392, validation Accuracy= 27.000%\n",
      "Epoch 28, Average Training Loss= 1.410, Average Training Accuracy= 24.766%\n",
      "\n",
      "Iter 0, Loss= 1.401, Accuracy= 22.656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20, Loss= 1.412, Accuracy= 21.094\n",
      "Iter 40, Loss= 1.386, Accuracy= 29.688\n",
      "Iter 60, Loss= 1.401, Accuracy= 28.125\n",
      "\n",
      "Epoch 29, Validation Loss= 1.395, validation Accuracy= 25.500%\n",
      "Epoch 29, Average Training Loss= 1.405, Average Training Accuracy= 25.279%\n",
      "\n",
      "Iter 0, Loss= 1.395, Accuracy= 27.344\n",
      "Iter 20, Loss= 1.410, Accuracy= 24.219\n",
      "Iter 40, Loss= 1.372, Accuracy= 31.250\n",
      "Iter 60, Loss= 1.424, Accuracy= 25.781\n",
      "\n",
      "Epoch 30, Validation Loss= 1.396, validation Accuracy= 27.000%\n",
      "Epoch 30, Average Training Loss= 1.408, Average Training Accuracy= 25.871%\n",
      "\n",
      "Iter 0, Loss= 1.391, Accuracy= 27.344\n",
      "Iter 20, Loss= 1.407, Accuracy= 27.344\n",
      "Iter 40, Loss= 1.422, Accuracy= 21.094\n",
      "Iter 60, Loss= 1.417, Accuracy= 20.312\n",
      "\n",
      "Epoch 31, Validation Loss= 1.419, validation Accuracy= 25.500%\n",
      "Epoch 31, Average Training Loss= 1.406, Average Training Accuracy= 24.911%\n",
      "\n",
      "Iter 0, Loss= 1.423, Accuracy= 25.781\n",
      "Iter 20, Loss= 1.457, Accuracy= 21.094\n",
      "Iter 40, Loss= 1.421, Accuracy= 21.094\n",
      "Iter 60, Loss= 1.378, Accuracy= 29.688\n",
      "\n",
      "Epoch 32, Validation Loss= 1.394, validation Accuracy= 25.100%\n",
      "Epoch 32, Average Training Loss= 1.409, Average Training Accuracy= 24.475%\n",
      "\n",
      "Iter 0, Loss= 1.391, Accuracy= 25.000\n",
      "Iter 20, Loss= 1.370, Accuracy= 39.062\n",
      "Iter 40, Loss= 1.402, Accuracy= 38.281\n",
      "Iter 60, Loss= 1.302, Accuracy= 31.250\n",
      "\n",
      "Epoch 33, Validation Loss= 1.314, validation Accuracy= 34.600%\n",
      "Epoch 33, Average Training Loss= 1.337, Average Training Accuracy= 34.431%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.332, Accuracy= 35.156\n",
      "Iter 20, Loss= 1.266, Accuracy= 36.719\n",
      "Iter 40, Loss= 1.300, Accuracy= 33.594\n",
      "Iter 60, Loss= 1.191, Accuracy= 41.406\n",
      "\n",
      "Epoch 34, Validation Loss= 1.237, validation Accuracy= 43.500%\n",
      "Epoch 34, Average Training Loss= 1.266, Average Training Accuracy= 37.511%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.221, Accuracy= 44.531\n",
      "Iter 20, Loss= 1.311, Accuracy= 34.375\n",
      "Iter 40, Loss= 1.257, Accuracy= 32.812\n",
      "Iter 60, Loss= 1.214, Accuracy= 42.188\n",
      "\n",
      "Epoch 35, Validation Loss= 1.230, validation Accuracy= 41.500%\n",
      "Epoch 35, Average Training Loss= 1.240, Average Training Accuracy= 40.413%\n",
      "\n",
      "Iter 0, Loss= 1.274, Accuracy= 42.188\n",
      "Iter 20, Loss= 1.207, Accuracy= 46.875\n",
      "Iter 40, Loss= 1.206, Accuracy= 43.750\n",
      "Iter 60, Loss= 1.249, Accuracy= 43.750\n",
      "\n",
      "Epoch 36, Validation Loss= 1.186, validation Accuracy= 43.400%\n",
      "Epoch 36, Average Training Loss= 1.231, Average Training Accuracy= 41.607%\n",
      "\n",
      "Iter 0, Loss= 1.229, Accuracy= 39.844\n",
      "Iter 20, Loss= 1.154, Accuracy= 46.094\n",
      "Iter 40, Loss= 1.043, Accuracy= 53.125\n",
      "Iter 60, Loss= 1.116, Accuracy= 47.656\n",
      "\n",
      "Epoch 37, Validation Loss= 1.114, validation Accuracy= 40.600%\n",
      "Epoch 37, Average Training Loss= 1.165, Average Training Accuracy= 42.411%\n",
      "\n",
      "Iter 0, Loss= 1.179, Accuracy= 41.406\n",
      "Iter 20, Loss= 1.111, Accuracy= 46.875\n",
      "Iter 40, Loss= 1.063, Accuracy= 43.750\n",
      "Iter 60, Loss= 1.173, Accuracy= 36.719\n",
      "\n",
      "Epoch 38, Validation Loss= 1.145, validation Accuracy= 40.000%\n",
      "Epoch 38, Average Training Loss= 1.126, Average Training Accuracy= 42.801%\n",
      "\n",
      "Iter 0, Loss= 1.135, Accuracy= 42.969\n",
      "Iter 20, Loss= 1.092, Accuracy= 45.312\n",
      "Iter 40, Loss= 1.098, Accuracy= 50.000\n",
      "Iter 60, Loss= 1.057, Accuracy= 47.656\n",
      "\n",
      "Epoch 39, Validation Loss= 1.090, validation Accuracy= 44.400%\n",
      "Epoch 39, Average Training Loss= 1.102, Average Training Accuracy= 42.790%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.071, Accuracy= 44.531\n",
      "Iter 20, Loss= 1.036, Accuracy= 50.781\n",
      "Iter 40, Loss= 1.067, Accuracy= 50.781\n",
      "Iter 60, Loss= 1.107, Accuracy= 35.156\n",
      "\n",
      "Epoch 40, Validation Loss= 1.084, validation Accuracy= 44.100%\n",
      "Epoch 40, Average Training Loss= 1.094, Average Training Accuracy= 43.181%\n",
      "\n",
      "Iter 0, Loss= 1.103, Accuracy= 38.281\n",
      "Iter 20, Loss= 1.075, Accuracy= 42.969\n",
      "Iter 40, Loss= 1.070, Accuracy= 57.031\n",
      "Iter 60, Loss= 1.057, Accuracy= 42.969\n",
      "\n",
      "Epoch 41, Validation Loss= 1.072, validation Accuracy= 44.900%\n",
      "Epoch 41, Average Training Loss= 1.077, Average Training Accuracy= 45.826%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.094, Accuracy= 41.406\n",
      "Iter 20, Loss= 1.051, Accuracy= 41.406\n",
      "Iter 40, Loss= 1.029, Accuracy= 48.438\n",
      "Iter 60, Loss= 1.097, Accuracy= 39.062\n",
      "\n",
      "Epoch 42, Validation Loss= 1.032, validation Accuracy= 45.100%\n",
      "Epoch 42, Average Training Loss= 1.069, Average Training Accuracy= 44.163%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 1.059, Accuracy= 40.625\n",
      "Iter 20, Loss= 1.016, Accuracy= 52.344\n",
      "Iter 40, Loss= 1.025, Accuracy= 43.750\n",
      "Iter 60, Loss= 1.084, Accuracy= 44.531\n",
      "\n",
      "Epoch 43, Validation Loss= 1.022, validation Accuracy= 44.400%\n",
      "Epoch 43, Average Training Loss= 1.039, Average Training Accuracy= 45.357%\n",
      "\n",
      "Iter 0, Loss= 1.008, Accuracy= 48.438\n",
      "Iter 20, Loss= 1.039, Accuracy= 44.531\n",
      "Iter 40, Loss= 0.978, Accuracy= 50.781\n",
      "Iter 60, Loss= 0.973, Accuracy= 50.000\n",
      "\n",
      "Epoch 44, Validation Loss= 0.931, validation Accuracy= 48.900%\n",
      "Epoch 44, Average Training Loss= 0.988, Average Training Accuracy= 45.714%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 0.969, Accuracy= 50.000\n",
      "Iter 20, Loss= 1.038, Accuracy= 46.875\n",
      "Iter 40, Loss= 0.883, Accuracy= 48.438\n",
      "Iter 60, Loss= 0.855, Accuracy= 53.906\n",
      "\n",
      "Epoch 45, Validation Loss= 0.913, validation Accuracy= 48.400%\n",
      "Epoch 45, Average Training Loss= 0.949, Average Training Accuracy= 46.429%\n",
      "\n",
      "Iter 0, Loss= 0.898, Accuracy= 49.219\n",
      "Iter 20, Loss= 0.922, Accuracy= 45.312\n",
      "Iter 40, Loss= 0.894, Accuracy= 54.688\n",
      "Iter 60, Loss= 0.956, Accuracy= 44.531\n",
      "\n",
      "Epoch 46, Validation Loss= 0.939, validation Accuracy= 43.000%\n",
      "Epoch 46, Average Training Loss= 0.933, Average Training Accuracy= 46.004%\n",
      "\n",
      "Iter 0, Loss= 0.925, Accuracy= 47.656\n",
      "Iter 20, Loss= 0.916, Accuracy= 47.656\n",
      "Iter 40, Loss= 0.927, Accuracy= 45.312\n",
      "Iter 60, Loss= 0.874, Accuracy= 48.438\n",
      "\n",
      "Epoch 47, Validation Loss= 0.931, validation Accuracy= 42.500%\n",
      "Epoch 47, Average Training Loss= 0.931, Average Training Accuracy= 45.893%\n",
      "\n",
      "Iter 0, Loss= 0.987, Accuracy= 41.406\n",
      "Iter 20, Loss= 0.961, Accuracy= 37.500\n",
      "Iter 40, Loss= 0.906, Accuracy= 46.094\n",
      "Iter 60, Loss= 0.909, Accuracy= 46.094\n",
      "\n",
      "Epoch 48, Validation Loss= 0.904, validation Accuracy= 47.700%\n",
      "Epoch 48, Average Training Loss= 0.921, Average Training Accuracy= 46.618%\n",
      "\n",
      "Iter 0, Loss= 0.888, Accuracy= 49.219\n",
      "Iter 20, Loss= 0.877, Accuracy= 48.438\n",
      "Iter 40, Loss= 0.936, Accuracy= 41.406\n",
      "Iter 60, Loss= 0.997, Accuracy= 41.406\n",
      "\n",
      "Epoch 49, Validation Loss= 0.917, validation Accuracy= 45.900%\n",
      "Epoch 49, Average Training Loss= 0.927, Average Training Accuracy= 45.123%\n",
      "\n",
      "Iter 0, Loss= 0.949, Accuracy= 37.500\n",
      "Iter 20, Loss= 0.886, Accuracy= 50.781\n",
      "Iter 40, Loss= 0.884, Accuracy= 49.219\n",
      "Iter 60, Loss= 0.950, Accuracy= 45.312\n",
      "\n",
      "Epoch 50, Validation Loss= 0.914, validation Accuracy= 47.200%\n",
      "Epoch 50, Average Training Loss= 0.923, Average Training Accuracy= 46.440%\n",
      "\n",
      "Iter 0, Loss= 0.995, Accuracy= 47.656\n",
      "Iter 20, Loss= 0.869, Accuracy= 46.875\n",
      "Iter 40, Loss= 0.900, Accuracy= 45.312\n",
      "Iter 60, Loss= 0.872, Accuracy= 50.781\n",
      "\n",
      "Epoch 51, Validation Loss= 0.914, validation Accuracy= 46.300%\n",
      "Epoch 51, Average Training Loss= 0.910, Average Training Accuracy= 46.663%\n",
      "\n",
      "Iter 0, Loss= 0.906, Accuracy= 53.125\n",
      "Iter 20, Loss= 0.937, Accuracy= 49.219\n",
      "Iter 40, Loss= 0.869, Accuracy= 48.438\n",
      "Iter 60, Loss= 0.852, Accuracy= 54.688\n",
      "\n",
      "Epoch 52, Validation Loss= 0.914, validation Accuracy= 45.700%\n",
      "Epoch 52, Average Training Loss= 0.906, Average Training Accuracy= 47.533%\n",
      "\n",
      "Iter 0, Loss= 0.873, Accuracy= 45.312\n",
      "Iter 20, Loss= 0.933, Accuracy= 46.875\n",
      "Iter 40, Loss= 0.933, Accuracy= 43.750\n",
      "Iter 60, Loss= 0.979, Accuracy= 35.938\n",
      "\n",
      "Epoch 53, Validation Loss= 0.925, validation Accuracy= 45.600%\n",
      "Epoch 53, Average Training Loss= 0.913, Average Training Accuracy= 46.250%\n",
      "\n",
      "Iter 0, Loss= 0.930, Accuracy= 48.438\n",
      "Iter 20, Loss= 0.906, Accuracy= 42.969\n",
      "Iter 40, Loss= 0.893, Accuracy= 42.188\n",
      "Iter 60, Loss= 0.970, Accuracy= 43.750\n",
      "\n",
      "Epoch 54, Validation Loss= 0.921, validation Accuracy= 43.700%\n",
      "Epoch 54, Average Training Loss= 0.911, Average Training Accuracy= 46.440%\n",
      "\n",
      "Iter 0, Loss= 0.948, Accuracy= 39.062\n",
      "Iter 20, Loss= 0.883, Accuracy= 45.312\n",
      "Iter 40, Loss= 0.886, Accuracy= 53.906\n",
      "Iter 60, Loss= 0.890, Accuracy= 46.094\n",
      "\n",
      "Epoch 55, Validation Loss= 0.921, validation Accuracy= 42.900%\n",
      "Epoch 55, Average Training Loss= 0.904, Average Training Accuracy= 46.920%\n",
      "\n",
      "Iter 0, Loss= 0.911, Accuracy= 49.219\n",
      "Iter 20, Loss= 0.903, Accuracy= 50.000\n",
      "Iter 40, Loss= 0.929, Accuracy= 43.750\n",
      "Iter 60, Loss= 0.906, Accuracy= 47.656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 56, Validation Loss= 0.929, validation Accuracy= 43.000%\n",
      "Epoch 56, Average Training Loss= 0.906, Average Training Accuracy= 46.842%\n",
      "\n",
      "Iter 0, Loss= 0.904, Accuracy= 45.312\n",
      "Iter 20, Loss= 1.013, Accuracy= 38.281\n",
      "Iter 40, Loss= 0.848, Accuracy= 45.312\n",
      "Iter 60, Loss= 0.827, Accuracy= 54.688\n",
      "\n",
      "Epoch 57, Validation Loss= 0.918, validation Accuracy= 46.600%\n",
      "Epoch 57, Average Training Loss= 0.903, Average Training Accuracy= 48.728%\n",
      "\n",
      "Iter 0, Loss= 0.886, Accuracy= 45.312\n",
      "Iter 20, Loss= 0.887, Accuracy= 53.125\n",
      "Iter 40, Loss= 0.938, Accuracy= 43.750\n",
      "Iter 60, Loss= 0.958, Accuracy= 46.094\n",
      "\n",
      "Epoch 58, Validation Loss= 0.910, validation Accuracy= 47.000%\n",
      "Epoch 58, Average Training Loss= 0.914, Average Training Accuracy= 47.478%\n",
      "\n",
      "Iter 0, Loss= 0.854, Accuracy= 52.344\n",
      "Iter 20, Loss= 0.912, Accuracy= 48.438\n",
      "Iter 40, Loss= 0.948, Accuracy= 46.094\n",
      "Iter 60, Loss= 0.955, Accuracy= 44.531\n",
      "\n",
      "Epoch 59, Validation Loss= 0.898, validation Accuracy= 47.400%\n",
      "Epoch 59, Average Training Loss= 0.908, Average Training Accuracy= 47.500%\n",
      "\n",
      "Iter 0, Loss= 0.875, Accuracy= 54.688\n",
      "Iter 20, Loss= 0.898, Accuracy= 46.094\n",
      "Iter 40, Loss= 0.885, Accuracy= 46.875\n",
      "Iter 60, Loss= 0.905, Accuracy= 51.562\n",
      "\n",
      "Epoch 60, Validation Loss= 0.898, validation Accuracy= 48.700%\n",
      "Epoch 60, Average Training Loss= 0.903, Average Training Accuracy= 48.147%\n",
      "\n",
      "Iter 0, Loss= 0.839, Accuracy= 45.312\n",
      "Iter 20, Loss= 0.929, Accuracy= 48.438\n",
      "Iter 40, Loss= 0.933, Accuracy= 37.500\n",
      "Iter 60, Loss= 0.934, Accuracy= 44.531\n",
      "\n",
      "Epoch 61, Validation Loss= 0.921, validation Accuracy= 45.500%\n",
      "Epoch 61, Average Training Loss= 0.905, Average Training Accuracy= 46.842%\n",
      "\n",
      "Iter 0, Loss= 0.931, Accuracy= 46.875\n",
      "Iter 20, Loss= 0.834, Accuracy= 56.250\n",
      "Iter 40, Loss= 0.911, Accuracy= 47.656\n",
      "Iter 60, Loss= 0.917, Accuracy= 49.219\n",
      "\n",
      "Epoch 62, Validation Loss= 0.927, validation Accuracy= 45.500%\n",
      "Epoch 62, Average Training Loss= 0.900, Average Training Accuracy= 47.779%\n",
      "\n",
      "Iter 0, Loss= 0.878, Accuracy= 45.312\n",
      "Iter 20, Loss= 0.908, Accuracy= 47.656\n",
      "Iter 40, Loss= 0.917, Accuracy= 41.406\n",
      "Iter 60, Loss= 0.946, Accuracy= 49.219\n",
      "\n",
      "Epoch 63, Validation Loss= 0.928, validation Accuracy= 44.200%\n",
      "Epoch 63, Average Training Loss= 0.897, Average Training Accuracy= 48.092%\n",
      "\n",
      "Iter 0, Loss= 0.861, Accuracy= 46.875\n",
      "Iter 20, Loss= 0.843, Accuracy= 57.031\n",
      "Iter 40, Loss= 0.926, Accuracy= 39.062\n",
      "Iter 60, Loss= 0.873, Accuracy= 57.031\n",
      "\n",
      "Epoch 64, Validation Loss= 0.921, validation Accuracy= 45.800%\n",
      "Epoch 64, Average Training Loss= 0.898, Average Training Accuracy= 48.103%\n",
      "\n",
      "Iter 0, Loss= 0.828, Accuracy= 53.906\n",
      "Iter 20, Loss= 0.903, Accuracy= 45.312\n",
      "Iter 40, Loss= 0.950, Accuracy= 42.969\n",
      "Iter 60, Loss= 0.902, Accuracy= 44.531\n",
      "\n",
      "Epoch 65, Validation Loss= 0.911, validation Accuracy= 46.000%\n",
      "Epoch 65, Average Training Loss= 0.898, Average Training Accuracy= 48.739%\n",
      "\n",
      "Iter 0, Loss= 0.965, Accuracy= 39.062\n",
      "Iter 20, Loss= 0.908, Accuracy= 53.906\n",
      "Iter 40, Loss= 0.934, Accuracy= 42.188\n",
      "Iter 60, Loss= 0.873, Accuracy= 52.344\n",
      "\n",
      "Epoch 66, Validation Loss= 0.905, validation Accuracy= 46.700%\n",
      "Epoch 66, Average Training Loss= 0.895, Average Training Accuracy= 48.750%\n",
      "\n",
      "Iter 0, Loss= 0.903, Accuracy= 41.406\n",
      "Iter 20, Loss= 0.916, Accuracy= 44.531\n",
      "Iter 40, Loss= 0.953, Accuracy= 48.438\n",
      "Iter 60, Loss= 0.911, Accuracy= 50.000\n",
      "\n",
      "Epoch 67, Validation Loss= 0.920, validation Accuracy= 46.300%\n",
      "Epoch 67, Average Training Loss= 0.895, Average Training Accuracy= 48.817%\n",
      "\n",
      "Iter 0, Loss= 0.851, Accuracy= 49.219\n",
      "Iter 20, Loss= 0.875, Accuracy= 51.562\n",
      "Iter 40, Loss= 0.942, Accuracy= 45.312\n",
      "Iter 60, Loss= 0.931, Accuracy= 46.875\n",
      "\n",
      "Epoch 68, Validation Loss= 0.927, validation Accuracy= 46.200%\n",
      "Epoch 68, Average Training Loss= 0.897, Average Training Accuracy= 48.359%\n",
      "\n",
      "Iter 0, Loss= 0.944, Accuracy= 36.719\n",
      "Iter 20, Loss= 0.920, Accuracy= 46.094\n",
      "Iter 40, Loss= 0.905, Accuracy= 43.750\n",
      "Iter 60, Loss= 0.948, Accuracy= 50.781\n",
      "\n",
      "Epoch 69, Validation Loss= 0.911, validation Accuracy= 45.400%\n",
      "Epoch 69, Average Training Loss= 0.894, Average Training Accuracy= 49.219%\n",
      "\n",
      "Iter 0, Loss= 0.846, Accuracy= 54.688\n",
      "Iter 20, Loss= 0.857, Accuracy= 55.469\n",
      "Iter 40, Loss= 0.915, Accuracy= 45.312\n",
      "Iter 60, Loss= 0.902, Accuracy= 51.562\n",
      "\n",
      "Epoch 70, Validation Loss= 0.951, validation Accuracy= 44.700%\n",
      "Epoch 70, Average Training Loss= 0.894, Average Training Accuracy= 48.873%\n",
      "\n",
      "Iter 0, Loss= 0.942, Accuracy= 44.531\n",
      "Iter 20, Loss= 0.912, Accuracy= 50.781\n",
      "Iter 40, Loss= 0.923, Accuracy= 45.312\n",
      "Iter 60, Loss= 0.905, Accuracy= 49.219\n",
      "\n",
      "Epoch 71, Validation Loss= 0.919, validation Accuracy= 46.800%\n",
      "Epoch 71, Average Training Loss= 0.891, Average Training Accuracy= 48.728%\n",
      "\n",
      "Iter 0, Loss= 0.906, Accuracy= 49.219\n",
      "Iter 20, Loss= 0.908, Accuracy= 50.781\n",
      "Iter 40, Loss= 0.910, Accuracy= 44.531\n",
      "Iter 60, Loss= 0.967, Accuracy= 42.969\n",
      "\n",
      "Epoch 72, Validation Loss= 0.906, validation Accuracy= 49.600%\n",
      "Epoch 72, Average Training Loss= 0.887, Average Training Accuracy= 50.491%\n",
      "Checkpoint created!\n",
      "\n",
      "Iter 0, Loss= 0.866, Accuracy= 57.031\n",
      "Iter 20, Loss= 0.883, Accuracy= 56.250\n",
      "Iter 40, Loss= 0.861, Accuracy= 51.562\n",
      "Iter 60, Loss= 0.891, Accuracy= 49.219\n",
      "\n",
      "Epoch 73, Validation Loss= 0.912, validation Accuracy= 47.800%\n",
      "Epoch 73, Average Training Loss= 0.884, Average Training Accuracy= 50.837%\n",
      "\n",
      "Iter 0, Loss= 0.907, Accuracy= 45.312\n",
      "Iter 20, Loss= 0.923, Accuracy= 41.406\n",
      "Iter 40, Loss= 0.874, Accuracy= 42.188\n",
      "Iter 60, Loss= 0.908, Accuracy= 47.656\n",
      "\n",
      "Epoch 74, Validation Loss= 0.930, validation Accuracy= 43.900%\n",
      "Epoch 74, Average Training Loss= 0.887, Average Training Accuracy= 49.475%\n",
      "\n",
      "Iter 0, Loss= 0.930, Accuracy= 45.312\n",
      "Iter 20, Loss= 0.942, Accuracy= 45.312\n",
      "Iter 40, Loss= 0.874, Accuracy= 50.000\n",
      "Iter 60, Loss= 0.870, Accuracy= 56.250\n",
      "\n",
      "Epoch 75, Validation Loss= 0.925, validation Accuracy= 46.800%\n",
      "Epoch 75, Average Training Loss= 0.887, Average Training Accuracy= 50.100%\n",
      "\n",
      "Iter 0, Loss= 0.851, Accuracy= 55.469\n",
      "Iter 20, Loss= 0.807, Accuracy= 53.125\n",
      "Iter 40, Loss= 0.901, Accuracy= 48.438\n",
      "Iter 60, Loss= 0.883, Accuracy= 49.219\n",
      "\n",
      "Epoch 76, Validation Loss= 0.941, validation Accuracy= 48.500%\n",
      "Epoch 76, Average Training Loss= 0.883, Average Training Accuracy= 50.402%\n",
      "\n",
      "Iter 0, Loss= 0.927, Accuracy= 43.750\n",
      "Iter 20, Loss= 0.946, Accuracy= 41.406\n",
      "Iter 40, Loss= 0.909, Accuracy= 49.219\n",
      "Iter 60, Loss= 0.856, Accuracy= 53.125\n",
      "\n",
      "Epoch 77, Validation Loss= 0.937, validation Accuracy= 45.600%\n",
      "Epoch 77, Average Training Loss= 0.885, Average Training Accuracy= 50.179%\n",
      "\n",
      "Iter 0, Loss= 0.929, Accuracy= 50.000\n",
      "Iter 20, Loss= 0.874, Accuracy= 60.156\n",
      "Iter 40, Loss= 0.860, Accuracy= 52.344\n",
      "Iter 60, Loss= 0.924, Accuracy= 50.781\n",
      "\n",
      "Epoch 78, Validation Loss= 0.932, validation Accuracy= 46.500%\n",
      "Epoch 78, Average Training Loss= 0.879, Average Training Accuracy= 51.462%\n",
      "\n",
      "Iter 0, Loss= 0.860, Accuracy= 52.344\n",
      "Iter 20, Loss= 0.885, Accuracy= 53.125\n",
      "Iter 40, Loss= 0.820, Accuracy= 55.469\n",
      "Iter 60, Loss= 0.892, Accuracy= 50.781\n",
      "\n",
      "Epoch 79, Validation Loss= 0.933, validation Accuracy= 44.900%\n",
      "Epoch 79, Average Training Loss= 0.880, Average Training Accuracy= 50.725%\n",
      "\n",
      "Iter 0, Loss= 0.838, Accuracy= 55.469\n",
      "Iter 20, Loss= 0.816, Accuracy= 57.031\n",
      "Iter 40, Loss= 0.948, Accuracy= 43.750\n",
      "Iter 60, Loss= 0.826, Accuracy= 61.719\n",
      "\n",
      "Epoch 80, Validation Loss= 0.934, validation Accuracy= 46.600%\n",
      "Epoch 80, Average Training Loss= 0.877, Average Training Accuracy= 52.031%\n",
      "\n",
      "Iter 0, Loss= 0.844, Accuracy= 53.125\n",
      "Iter 20, Loss= 0.854, Accuracy= 53.125\n",
      "Iter 40, Loss= 0.881, Accuracy= 48.438\n",
      "Iter 60, Loss= 0.931, Accuracy= 48.438\n",
      "\n",
      "Epoch 81, Validation Loss= 0.942, validation Accuracy= 48.000%\n",
      "Epoch 81, Average Training Loss= 0.874, Average Training Accuracy= 51.261%\n",
      "\n",
      "Iter 0, Loss= 0.873, Accuracy= 58.594\n",
      "Iter 20, Loss= 0.883, Accuracy= 53.906\n",
      "Iter 40, Loss= 0.859, Accuracy= 54.688\n",
      "Iter 60, Loss= 0.920, Accuracy= 50.781\n",
      "\n",
      "Epoch 82, Validation Loss= 0.940, validation Accuracy= 48.200%\n",
      "Epoch 82, Average Training Loss= 0.875, Average Training Accuracy= 51.775%\n",
      "\n",
      "Iter 0, Loss= 0.855, Accuracy= 51.562\n",
      "Iter 20, Loss= 0.814, Accuracy= 53.125\n",
      "Iter 40, Loss= 0.890, Accuracy= 47.656\n",
      "Iter 60, Loss= 0.914, Accuracy= 50.000\n",
      "\n",
      "Epoch 83, Validation Loss= 0.950, validation Accuracy= 45.800%\n",
      "Epoch 83, Average Training Loss= 0.868, Average Training Accuracy= 52.333%\n",
      "\n",
      "Iter 0, Loss= 0.850, Accuracy= 48.438\n",
      "Iter 20, Loss= 0.893, Accuracy= 51.562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40, Loss= 0.792, Accuracy= 60.156\n",
      "Iter 60, Loss= 0.884, Accuracy= 49.219\n",
      "\n",
      "Epoch 84, Validation Loss= 0.940, validation Accuracy= 46.900%\n",
      "Epoch 84, Average Training Loss= 0.874, Average Training Accuracy= 52.489%\n",
      "\n",
      "Iter 0, Loss= 0.917, Accuracy= 46.094\n",
      "Iter 20, Loss= 0.892, Accuracy= 53.125\n",
      "Iter 40, Loss= 0.907, Accuracy= 54.688\n",
      "Iter 60, Loss= 0.872, Accuracy= 48.438\n",
      "\n",
      "Epoch 85, Validation Loss= 0.937, validation Accuracy= 47.000%\n",
      "Epoch 85, Average Training Loss= 0.868, Average Training Accuracy= 53.225%\n",
      "\n",
      "Iter 0, Loss= 0.870, Accuracy= 52.344\n",
      "Iter 20, Loss= 0.879, Accuracy= 52.344\n",
      "Iter 40, Loss= 0.947, Accuracy= 49.219\n",
      "Iter 60, Loss= 0.841, Accuracy= 57.031\n",
      "\n",
      "Epoch 86, Validation Loss= 0.950, validation Accuracy= 46.200%\n",
      "Epoch 86, Average Training Loss= 0.866, Average Training Accuracy= 53.304%\n",
      "\n",
      "Iter 0, Loss= 0.838, Accuracy= 57.031\n",
      "Iter 20, Loss= 0.947, Accuracy= 48.438\n",
      "Iter 40, Loss= 0.842, Accuracy= 59.375\n",
      "Iter 60, Loss= 0.883, Accuracy= 50.781\n",
      "\n",
      "Epoch 87, Validation Loss= 0.976, validation Accuracy= 46.200%\n",
      "Epoch 87, Average Training Loss= 0.855, Average Training Accuracy= 54.464%\n",
      "\n",
      "Iter 0, Loss= 0.822, Accuracy= 60.938\n",
      "Iter 20, Loss= 0.847, Accuracy= 51.562\n",
      "Iter 40, Loss= 0.866, Accuracy= 53.906\n",
      "Iter 60, Loss= 0.917, Accuracy= 42.969\n",
      "\n",
      "Epoch 88, Validation Loss= 0.972, validation Accuracy= 44.600%\n",
      "Epoch 88, Average Training Loss= 0.846, Average Training Accuracy= 55.145%\n",
      "\n",
      "Iter 0, Loss= 0.749, Accuracy= 61.719\n",
      "Iter 20, Loss= 0.881, Accuracy= 50.000\n",
      "Iter 40, Loss= 0.880, Accuracy= 55.469\n",
      "Iter 60, Loss= 0.843, Accuracy= 50.781\n",
      "\n",
      "Epoch 89, Validation Loss= 1.014, validation Accuracy= 47.000%\n",
      "Epoch 89, Average Training Loss= 0.847, Average Training Accuracy= 54.621%\n",
      "\n",
      "Iter 0, Loss= 0.794, Accuracy= 63.281\n",
      "Iter 20, Loss= 0.863, Accuracy= 50.781\n",
      "Iter 40, Loss= 0.877, Accuracy= 53.906\n",
      "Iter 60, Loss= 0.854, Accuracy= 53.125\n",
      "\n",
      "Epoch 90, Validation Loss= 0.950, validation Accuracy= 46.600%\n",
      "Epoch 90, Average Training Loss= 0.851, Average Training Accuracy= 54.710%\n",
      "\n",
      "Iter 0, Loss= 0.868, Accuracy= 57.031\n",
      "Iter 20, Loss= 0.896, Accuracy= 50.000\n",
      "Iter 40, Loss= 0.813, Accuracy= 57.812\n",
      "Iter 60, Loss= 0.846, Accuracy= 54.688\n",
      "\n",
      "Epoch 91, Validation Loss= 0.979, validation Accuracy= 46.200%\n",
      "Epoch 91, Average Training Loss= 0.833, Average Training Accuracy= 56.150%\n",
      "\n",
      "Iter 0, Loss= 0.780, Accuracy= 64.062\n",
      "Iter 20, Loss= 0.850, Accuracy= 55.469\n",
      "Iter 40, Loss= 0.825, Accuracy= 57.812\n",
      "Iter 60, Loss= 0.842, Accuracy= 54.688\n",
      "\n",
      "Epoch 92, Validation Loss= 1.016, validation Accuracy= 44.700%\n",
      "Epoch 92, Average Training Loss= 0.829, Average Training Accuracy= 56.641%\n",
      "\n",
      "Iter 0, Loss= 0.813, Accuracy= 54.688\n",
      "Iter 20, Loss= 0.848, Accuracy= 56.250\n",
      "Iter 40, Loss= 0.765, Accuracy= 64.062\n",
      "Iter 60, Loss= 0.837, Accuracy= 51.562\n",
      "\n",
      "Epoch 93, Validation Loss= 1.062, validation Accuracy= 46.000%\n",
      "Epoch 93, Average Training Loss= 0.824, Average Training Accuracy= 57.656%\n",
      "\n",
      "Iter 0, Loss= 0.783, Accuracy= 53.125\n",
      "Iter 20, Loss= 0.717, Accuracy= 66.406\n",
      "Iter 40, Loss= 0.863, Accuracy= 57.031\n",
      "Iter 60, Loss= 0.865, Accuracy= 55.469\n",
      "\n",
      "Epoch 94, Validation Loss= 0.989, validation Accuracy= 47.200%\n",
      "Epoch 94, Average Training Loss= 0.817, Average Training Accuracy= 57.511%\n",
      "\n",
      "Iter 0, Loss= 0.806, Accuracy= 60.938\n",
      "Iter 20, Loss= 0.769, Accuracy= 57.031\n",
      "Iter 40, Loss= 0.823, Accuracy= 52.344\n",
      "Iter 60, Loss= 0.768, Accuracy= 60.938\n",
      "\n",
      "Epoch 95, Validation Loss= 1.047, validation Accuracy= 47.200%\n",
      "Epoch 95, Average Training Loss= 0.814, Average Training Accuracy= 58.482%\n",
      "\n",
      "Iter 0, Loss= 0.796, Accuracy= 61.719\n",
      "Iter 20, Loss= 0.809, Accuracy= 53.125\n",
      "Iter 40, Loss= 0.744, Accuracy= 62.500\n",
      "Iter 60, Loss= 0.780, Accuracy= 61.719\n",
      "\n",
      "Epoch 96, Validation Loss= 1.050, validation Accuracy= 46.700%\n",
      "Epoch 96, Average Training Loss= 0.801, Average Training Accuracy= 59.754%\n",
      "\n",
      "Iter 0, Loss= 0.839, Accuracy= 58.594\n",
      "Iter 20, Loss= 0.752, Accuracy= 58.594\n",
      "Iter 40, Loss= 0.734, Accuracy= 63.281\n",
      "Iter 60, Loss= 0.780, Accuracy= 59.375\n",
      "\n",
      "Epoch 97, Validation Loss= 1.066, validation Accuracy= 46.400%\n",
      "Epoch 97, Average Training Loss= 0.791, Average Training Accuracy= 60.893%\n",
      "\n",
      "Iter 0, Loss= 0.793, Accuracy= 58.594\n",
      "Iter 20, Loss= 0.791, Accuracy= 64.062\n",
      "Iter 40, Loss= 0.801, Accuracy= 58.594\n",
      "Iter 60, Loss= 0.832, Accuracy= 58.594\n",
      "\n",
      "Epoch 98, Validation Loss= 1.082, validation Accuracy= 45.500%\n",
      "Epoch 98, Average Training Loss= 0.782, Average Training Accuracy= 61.306%\n",
      "\n",
      "Iter 0, Loss= 0.762, Accuracy= 60.156\n",
      "Iter 20, Loss= 0.774, Accuracy= 62.500\n",
      "Iter 40, Loss= 0.804, Accuracy= 59.375\n",
      "Iter 60, Loss= 0.817, Accuracy= 62.500\n",
      "\n",
      "Epoch 99, Validation Loss= 1.119, validation Accuracy= 45.300%\n",
      "Epoch 99, Average Training Loss= 0.781, Average Training Accuracy= 61.853%\n",
      "\n",
      "Iter 0, Loss= 0.754, Accuracy= 60.156\n",
      "Iter 20, Loss= 0.781, Accuracy= 62.500\n",
      "Iter 40, Loss= 0.800, Accuracy= 57.812\n",
      "Iter 60, Loss= 0.809, Accuracy= 63.281\n",
      "\n",
      "Epoch 100, Validation Loss= 1.143, validation Accuracy= 45.700%\n",
      "Epoch 100, Average Training Loss= 0.769, Average Training Accuracy= 62.221%\n",
      "\n",
      "Iter 0, Loss= 0.741, Accuracy= 60.938\n",
      "Iter 20, Loss= 0.757, Accuracy= 61.719\n",
      "Iter 40, Loss= 0.819, Accuracy= 60.156\n",
      "Iter 60, Loss= 0.721, Accuracy= 68.750\n",
      "\n",
      "Epoch 101, Validation Loss= 1.227, validation Accuracy= 46.100%\n",
      "Epoch 101, Average Training Loss= 0.753, Average Training Accuracy= 63.583%\n",
      "\n",
      "Iter 0, Loss= 0.723, Accuracy= 67.188\n",
      "Iter 20, Loss= 0.721, Accuracy= 67.969\n",
      "Iter 40, Loss= 0.783, Accuracy= 60.156\n",
      "Iter 60, Loss= 0.797, Accuracy= 62.500\n",
      "\n",
      "Epoch 102, Validation Loss= 1.131, validation Accuracy= 44.500%\n",
      "Epoch 102, Average Training Loss= 0.742, Average Training Accuracy= 64.442%\n",
      "\n",
      "Iter 0, Loss= 0.640, Accuracy= 71.094\n",
      "Iter 20, Loss= 0.728, Accuracy= 64.062\n",
      "Iter 40, Loss= 0.713, Accuracy= 64.062\n",
      "Iter 60, Loss= 0.700, Accuracy= 66.406\n",
      "\n",
      "Epoch 103, Validation Loss= 1.186, validation Accuracy= 45.800%\n",
      "Epoch 103, Average Training Loss= 0.731, Average Training Accuracy= 64.844%\n",
      "\n",
      "Iter 0, Loss= 0.671, Accuracy= 67.969\n",
      "Iter 20, Loss= 0.681, Accuracy= 64.062\n",
      "Iter 40, Loss= 0.767, Accuracy= 64.062\n",
      "Iter 60, Loss= 0.710, Accuracy= 71.875\n",
      "\n",
      "Epoch 104, Validation Loss= 1.239, validation Accuracy= 44.100%\n",
      "Epoch 104, Average Training Loss= 0.712, Average Training Accuracy= 66.819%\n",
      "\n",
      "Iter 0, Loss= 0.647, Accuracy= 71.875\n",
      "Iter 20, Loss= 0.635, Accuracy= 77.344\n",
      "Iter 40, Loss= 0.735, Accuracy= 66.406\n",
      "Iter 60, Loss= 0.712, Accuracy= 71.094\n",
      "\n",
      "Epoch 105, Validation Loss= 1.307, validation Accuracy= 45.200%\n",
      "Epoch 105, Average Training Loss= 0.709, Average Training Accuracy= 66.585%\n",
      "\n",
      "Iter 0, Loss= 0.681, Accuracy= 67.188\n",
      "Iter 20, Loss= 0.723, Accuracy= 67.188\n",
      "Iter 40, Loss= 0.685, Accuracy= 67.969\n",
      "Iter 60, Loss= 0.665, Accuracy= 75.781\n",
      "\n",
      "Epoch 106, Validation Loss= 1.317, validation Accuracy= 43.900%\n",
      "Epoch 106, Average Training Loss= 0.684, Average Training Accuracy= 68.739%\n",
      "\n",
      "Iter 0, Loss= 0.707, Accuracy= 70.312\n",
      "Iter 20, Loss= 0.704, Accuracy= 63.281\n",
      "Iter 40, Loss= 0.733, Accuracy= 62.500\n",
      "Iter 60, Loss= 0.675, Accuracy= 71.875\n",
      "\n",
      "Epoch 107, Validation Loss= 1.406, validation Accuracy= 45.400%\n",
      "Epoch 107, Average Training Loss= 0.675, Average Training Accuracy= 69.665%\n",
      "\n",
      "Iter 0, Loss= 0.749, Accuracy= 64.062\n",
      "Iter 20, Loss= 0.658, Accuracy= 71.875\n",
      "Iter 40, Loss= 0.642, Accuracy= 71.875\n",
      "Iter 60, Loss= 0.624, Accuracy= 71.875\n",
      "\n",
      "Epoch 108, Validation Loss= 1.354, validation Accuracy= 45.100%\n",
      "Epoch 108, Average Training Loss= 0.653, Average Training Accuracy= 71.016%\n",
      "\n",
      "Iter 0, Loss= 0.664, Accuracy= 73.438\n",
      "Iter 20, Loss= 0.660, Accuracy= 68.750\n",
      "Iter 40, Loss= 0.642, Accuracy= 72.656\n",
      "Iter 60, Loss= 0.668, Accuracy= 67.188\n",
      "\n",
      "Epoch 109, Validation Loss= 1.401, validation Accuracy= 45.200%\n",
      "Epoch 109, Average Training Loss= 0.642, Average Training Accuracy= 71.473%\n",
      "\n",
      "Iter 0, Loss= 0.700, Accuracy= 70.312\n",
      "Iter 20, Loss= 0.498, Accuracy= 79.688\n",
      "Iter 40, Loss= 0.587, Accuracy= 72.656\n",
      "Iter 60, Loss= 0.537, Accuracy= 75.000\n",
      "\n",
      "Epoch 110, Validation Loss= 1.356, validation Accuracy= 45.200%\n",
      "Epoch 110, Average Training Loss= 0.622, Average Training Accuracy= 73.036%\n",
      "\n",
      "Iter 0, Loss= 0.567, Accuracy= 79.688\n",
      "Iter 20, Loss= 0.522, Accuracy= 74.219\n",
      "Iter 40, Loss= 0.654, Accuracy= 66.406\n",
      "Iter 60, Loss= 0.672, Accuracy= 67.969\n",
      "\n",
      "Epoch 111, Validation Loss= 1.562, validation Accuracy= 46.300%\n",
      "Epoch 111, Average Training Loss= 0.612, Average Training Accuracy= 73.292%\n",
      "\n",
      "Iter 0, Loss= 0.558, Accuracy= 76.562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20, Loss= 0.550, Accuracy= 76.562\n",
      "Iter 40, Loss= 0.643, Accuracy= 71.094\n",
      "Iter 60, Loss= 0.583, Accuracy= 73.438\n",
      "\n",
      "Epoch 112, Validation Loss= 1.612, validation Accuracy= 44.200%\n",
      "Epoch 112, Average Training Loss= 0.594, Average Training Accuracy= 74.531%\n",
      "\n",
      "Iter 0, Loss= 0.520, Accuracy= 78.125\n",
      "Iter 20, Loss= 0.540, Accuracy= 77.344\n",
      "Iter 40, Loss= 0.545, Accuracy= 80.469\n",
      "Iter 60, Loss= 0.604, Accuracy= 75.000\n",
      "\n",
      "Epoch 113, Validation Loss= 1.580, validation Accuracy= 44.600%\n",
      "Epoch 113, Average Training Loss= 0.586, Average Training Accuracy= 75.491%\n",
      "\n",
      "Iter 0, Loss= 0.543, Accuracy= 74.219\n",
      "Iter 20, Loss= 0.632, Accuracy= 75.781\n",
      "Iter 40, Loss= 0.565, Accuracy= 78.125\n",
      "Iter 60, Loss= 0.624, Accuracy= 71.094\n",
      "\n",
      "Epoch 114, Validation Loss= 1.630, validation Accuracy= 44.400%\n",
      "Epoch 114, Average Training Loss= 0.576, Average Training Accuracy= 76.049%\n",
      "\n",
      "Iter 0, Loss= 0.519, Accuracy= 76.562\n",
      "Iter 20, Loss= 0.498, Accuracy= 77.344\n",
      "Iter 40, Loss= 0.511, Accuracy= 78.906\n",
      "Iter 60, Loss= 0.566, Accuracy= 76.562\n",
      "\n",
      "Epoch 115, Validation Loss= 1.698, validation Accuracy= 44.900%\n",
      "Epoch 115, Average Training Loss= 0.540, Average Training Accuracy= 78.147%\n",
      "\n",
      "Iter 0, Loss= 0.493, Accuracy= 84.375\n",
      "Iter 20, Loss= 0.576, Accuracy= 73.438\n",
      "Iter 40, Loss= 0.494, Accuracy= 78.125\n",
      "Iter 60, Loss= 0.578, Accuracy= 78.906\n",
      "\n",
      "Epoch 116, Validation Loss= 1.827, validation Accuracy= 44.600%\n",
      "Epoch 116, Average Training Loss= 0.519, Average Training Accuracy= 79.442%\n",
      "\n",
      "Iter 0, Loss= 0.535, Accuracy= 78.906\n",
      "Iter 20, Loss= 0.423, Accuracy= 82.812\n",
      "Iter 40, Loss= 0.504, Accuracy= 78.125\n",
      "Iter 60, Loss= 0.605, Accuracy= 71.875\n",
      "\n",
      "Epoch 117, Validation Loss= 1.898, validation Accuracy= 43.600%\n",
      "Epoch 117, Average Training Loss= 0.520, Average Training Accuracy= 79.219%\n",
      "\n",
      "Iter 0, Loss= 0.509, Accuracy= 78.906\n",
      "Iter 20, Loss= 0.514, Accuracy= 80.469\n",
      "Iter 40, Loss= 0.521, Accuracy= 82.812\n",
      "Iter 60, Loss= 0.502, Accuracy= 78.906\n",
      "\n",
      "Epoch 118, Validation Loss= 1.880, validation Accuracy= 44.300%\n",
      "Epoch 118, Average Training Loss= 0.499, Average Training Accuracy= 80.893%\n",
      "\n",
      "Iter 0, Loss= 0.491, Accuracy= 80.469\n",
      "Iter 20, Loss= 0.375, Accuracy= 86.719\n",
      "Iter 40, Loss= 0.432, Accuracy= 82.031\n",
      "Iter 60, Loss= 0.471, Accuracy= 82.812\n",
      "\n",
      "Epoch 119, Validation Loss= 1.895, validation Accuracy= 45.300%\n",
      "Epoch 119, Average Training Loss= 0.485, Average Training Accuracy= 81.842%\n",
      "\n",
      "Iter 0, Loss= 0.444, Accuracy= 82.031\n",
      "Iter 20, Loss= 0.453, Accuracy= 82.812\n",
      "Iter 40, Loss= 0.435, Accuracy= 78.906\n",
      "Iter 60, Loss= 0.517, Accuracy= 79.688\n",
      "\n",
      "Epoch 120, Validation Loss= 1.977, validation Accuracy= 44.700%\n",
      "Epoch 120, Average Training Loss= 0.469, Average Training Accuracy= 81.998%\n",
      "\n",
      "Iter 0, Loss= 0.451, Accuracy= 82.812\n",
      "Iter 20, Loss= 0.503, Accuracy= 78.906\n",
      "Iter 40, Loss= 0.467, Accuracy= 83.594\n",
      "Iter 60, Loss= 0.389, Accuracy= 83.594\n",
      "\n",
      "Epoch 121, Validation Loss= 1.938, validation Accuracy= 45.200%\n",
      "Epoch 121, Average Training Loss= 0.455, Average Training Accuracy= 83.080%\n",
      "\n",
      "Iter 0, Loss= 0.430, Accuracy= 85.156\n",
      "Iter 20, Loss= 0.456, Accuracy= 82.031\n",
      "Iter 40, Loss= 0.466, Accuracy= 78.906\n",
      "Iter 60, Loss= 0.536, Accuracy= 78.906\n",
      "\n",
      "Epoch 122, Validation Loss= 2.041, validation Accuracy= 44.800%\n",
      "Epoch 122, Average Training Loss= 0.468, Average Training Accuracy= 82.489%\n",
      "\n",
      "Iter 0, Loss= 0.439, Accuracy= 85.938\n",
      "Iter 20, Loss= 0.419, Accuracy= 84.375\n",
      "Iter 40, Loss= 0.471, Accuracy= 82.812\n",
      "Iter 60, Loss= 0.430, Accuracy= 84.375\n",
      "\n",
      "Epoch 123, Validation Loss= 2.201, validation Accuracy= 45.700%\n",
      "Epoch 123, Average Training Loss= 0.430, Average Training Accuracy= 84.330%\n",
      "\n",
      "Iter 0, Loss= 0.450, Accuracy= 82.031\n",
      "Iter 20, Loss= 0.362, Accuracy= 86.719\n",
      "Iter 40, Loss= 0.420, Accuracy= 85.938\n",
      "Iter 60, Loss= 0.420, Accuracy= 84.375\n",
      "\n",
      "Epoch 124, Validation Loss= 2.297, validation Accuracy= 45.500%\n",
      "Epoch 124, Average Training Loss= 0.417, Average Training Accuracy= 84.833%\n",
      "\n",
      "Iter 0, Loss= 0.451, Accuracy= 82.812\n",
      "Iter 20, Loss= 0.358, Accuracy= 89.844\n",
      "Iter 40, Loss= 0.352, Accuracy= 88.281\n",
      "Iter 60, Loss= 0.471, Accuracy= 81.250\n",
      "\n",
      "Epoch 125, Validation Loss= 2.328, validation Accuracy= 44.400%\n",
      "Epoch 125, Average Training Loss= 0.397, Average Training Accuracy= 85.904%\n",
      "\n",
      "Iter 0, Loss= 0.334, Accuracy= 89.062\n",
      "Iter 20, Loss= 0.435, Accuracy= 85.156\n",
      "Iter 40, Loss= 0.359, Accuracy= 85.156\n",
      "Iter 60, Loss= 0.378, Accuracy= 88.281\n",
      "\n",
      "Epoch 126, Validation Loss= 2.396, validation Accuracy= 43.600%\n",
      "Epoch 126, Average Training Loss= 0.398, Average Training Accuracy= 86.183%\n",
      "\n",
      "Iter 0, Loss= 0.379, Accuracy= 88.281\n",
      "Iter 20, Loss= 0.434, Accuracy= 82.812\n",
      "Iter 40, Loss= 0.437, Accuracy= 82.031\n",
      "Iter 60, Loss= 0.490, Accuracy= 82.812\n",
      "\n",
      "Epoch 127, Validation Loss= 2.516, validation Accuracy= 44.600%\n",
      "Epoch 127, Average Training Loss= 0.392, Average Training Accuracy= 86.842%\n",
      "\n",
      "Iter 0, Loss= 0.384, Accuracy= 89.062\n",
      "Iter 20, Loss= 0.391, Accuracy= 84.375\n",
      "Iter 40, Loss= 0.370, Accuracy= 88.281\n",
      "Iter 60, Loss= 0.459, Accuracy= 83.594\n",
      "\n",
      "Epoch 128, Validation Loss= 2.530, validation Accuracy= 47.600%\n",
      "Epoch 128, Average Training Loss= 0.377, Average Training Accuracy= 87.266%\n",
      "\n",
      "Iter 0, Loss= 0.296, Accuracy= 89.844\n",
      "Iter 20, Loss= 0.399, Accuracy= 82.812\n",
      "Iter 40, Loss= 0.376, Accuracy= 87.500\n",
      "Iter 60, Loss= 0.471, Accuracy= 82.812\n",
      "\n",
      "Epoch 129, Validation Loss= 2.505, validation Accuracy= 44.700%\n",
      "Epoch 129, Average Training Loss= 0.369, Average Training Accuracy= 87.533%\n",
      "\n",
      "Iter 0, Loss= 0.349, Accuracy= 86.719\n",
      "Iter 20, Loss= 0.253, Accuracy= 94.531\n",
      "Iter 40, Loss= 0.300, Accuracy= 90.625\n",
      "Iter 60, Loss= 0.362, Accuracy= 87.500\n",
      "\n",
      "Epoch 130, Validation Loss= 2.661, validation Accuracy= 45.400%\n",
      "Epoch 130, Average Training Loss= 0.340, Average Training Accuracy= 88.795%\n",
      "\n",
      "Iter 0, Loss= 0.283, Accuracy= 92.969\n",
      "Iter 20, Loss= 0.323, Accuracy= 91.406\n",
      "Iter 40, Loss= 0.232, Accuracy= 95.312\n",
      "Iter 60, Loss= 0.417, Accuracy= 87.500\n",
      "\n",
      "Epoch 131, Validation Loss= 2.657, validation Accuracy= 45.700%\n",
      "Epoch 131, Average Training Loss= 0.342, Average Training Accuracy= 89.085%\n",
      "\n",
      "Iter 0, Loss= 0.321, Accuracy= 87.500\n",
      "Iter 20, Loss= 0.349, Accuracy= 89.062\n",
      "Iter 40, Loss= 0.267, Accuracy= 92.188\n",
      "Iter 60, Loss= 0.453, Accuracy= 85.156\n",
      "\n",
      "Epoch 132, Validation Loss= 2.877, validation Accuracy= 43.100%\n",
      "Epoch 132, Average Training Loss= 0.341, Average Training Accuracy= 88.984%\n",
      "\n",
      "Iter 0, Loss= 0.327, Accuracy= 87.500\n",
      "Iter 20, Loss= 0.297, Accuracy= 92.188\n",
      "Iter 40, Loss= 0.411, Accuracy= 85.938\n",
      "Iter 60, Loss= 0.470, Accuracy= 82.812\n",
      "\n",
      "Epoch 133, Validation Loss= 2.745, validation Accuracy= 45.400%\n",
      "Epoch 133, Average Training Loss= 0.320, Average Training Accuracy= 90.424%\n",
      "\n",
      "Iter 0, Loss= 0.335, Accuracy= 92.188\n",
      "Iter 20, Loss= 0.335, Accuracy= 91.406\n",
      "Iter 40, Loss= 0.438, Accuracy= 85.938\n",
      "Iter 60, Loss= 0.317, Accuracy= 87.500\n",
      "\n",
      "Epoch 134, Validation Loss= 2.784, validation Accuracy= 43.800%\n",
      "Epoch 134, Average Training Loss= 0.341, Average Training Accuracy= 89.330%\n",
      "\n",
      "Iter 0, Loss= 0.295, Accuracy= 93.750\n",
      "Iter 20, Loss= 0.195, Accuracy= 97.656\n",
      "Iter 40, Loss= 0.318, Accuracy= 88.281\n",
      "Iter 60, Loss= 0.305, Accuracy= 92.969\n",
      "\n",
      "Epoch 135, Validation Loss= 2.825, validation Accuracy= 46.100%\n",
      "Epoch 135, Average Training Loss= 0.314, Average Training Accuracy= 90.949%\n",
      "\n",
      "Iter 0, Loss= 0.328, Accuracy= 89.062\n",
      "Iter 20, Loss= 0.375, Accuracy= 88.281\n",
      "Iter 40, Loss= 0.326, Accuracy= 89.062\n",
      "Iter 60, Loss= 0.264, Accuracy= 91.406\n",
      "\n",
      "Epoch 136, Validation Loss= 3.047, validation Accuracy= 44.400%\n",
      "Epoch 136, Average Training Loss= 0.307, Average Training Accuracy= 90.725%\n",
      "\n",
      "Iter 0, Loss= 0.278, Accuracy= 92.969\n",
      "Iter 20, Loss= 0.356, Accuracy= 87.500\n",
      "Iter 40, Loss= 0.348, Accuracy= 87.500\n",
      "Iter 60, Loss= 0.281, Accuracy= 92.188\n",
      "\n",
      "Epoch 137, Validation Loss= 2.845, validation Accuracy= 46.100%\n",
      "Epoch 137, Average Training Loss= 0.304, Average Training Accuracy= 91.250%\n",
      "\n",
      "Iter 0, Loss= 0.259, Accuracy= 95.312\n",
      "Iter 20, Loss= 0.269, Accuracy= 94.531\n",
      "Iter 40, Loss= 0.356, Accuracy= 91.406\n",
      "Iter 60, Loss= 0.263, Accuracy= 91.406\n",
      "\n",
      "Epoch 138, Validation Loss= 3.013, validation Accuracy= 46.100%\n",
      "Epoch 138, Average Training Loss= 0.287, Average Training Accuracy= 92.165%\n",
      "\n",
      "Iter 0, Loss= 0.295, Accuracy= 92.188\n",
      "Iter 20, Loss= 0.280, Accuracy= 89.844\n",
      "Iter 40, Loss= 0.295, Accuracy= 89.844\n",
      "Iter 60, Loss= 0.301, Accuracy= 92.188\n",
      "\n",
      "Epoch 139, Validation Loss= 3.087, validation Accuracy= 45.400%\n",
      "Epoch 139, Average Training Loss= 0.293, Average Training Accuracy= 91.763%\n",
      "\n",
      "Iter 0, Loss= 0.233, Accuracy= 91.406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20, Loss= 0.287, Accuracy= 90.625\n",
      "Iter 40, Loss= 0.264, Accuracy= 92.969\n",
      "Iter 60, Loss= 0.236, Accuracy= 94.531\n",
      "\n",
      "Epoch 140, Validation Loss= 3.299, validation Accuracy= 46.000%\n",
      "Epoch 140, Average Training Loss= 0.272, Average Training Accuracy= 92.723%\n",
      "\n",
      "Iter 0, Loss= 0.268, Accuracy= 93.750\n",
      "Iter 20, Loss= 0.222, Accuracy= 95.312\n",
      "Iter 40, Loss= 0.254, Accuracy= 93.750\n",
      "Iter 60, Loss= 0.263, Accuracy= 92.969\n",
      "\n",
      "Epoch 141, Validation Loss= 3.143, validation Accuracy= 43.400%\n",
      "Epoch 141, Average Training Loss= 0.264, Average Training Accuracy= 92.980%\n",
      "\n",
      "Iter 0, Loss= 0.219, Accuracy= 93.750\n",
      "Iter 20, Loss= 0.197, Accuracy= 96.094\n",
      "Iter 40, Loss= 0.355, Accuracy= 89.844\n",
      "Iter 60, Loss= 0.291, Accuracy= 91.406\n",
      "\n",
      "Epoch 142, Validation Loss= 3.181, validation Accuracy= 42.900%\n",
      "Epoch 142, Average Training Loss= 0.278, Average Training Accuracy= 92.734%\n",
      "\n",
      "Iter 0, Loss= 0.301, Accuracy= 90.625\n",
      "Iter 20, Loss= 0.217, Accuracy= 95.312\n",
      "Iter 40, Loss= 0.326, Accuracy= 89.844\n",
      "Iter 60, Loss= 0.308, Accuracy= 89.844\n",
      "\n",
      "Epoch 143, Validation Loss= 3.189, validation Accuracy= 45.400%\n",
      "Epoch 143, Average Training Loss= 0.277, Average Training Accuracy= 92.254%\n",
      "\n",
      "Iter 0, Loss= 0.232, Accuracy= 93.750\n",
      "Iter 20, Loss= 0.278, Accuracy= 91.406\n",
      "Iter 40, Loss= 0.221, Accuracy= 93.750\n",
      "Iter 60, Loss= 0.346, Accuracy= 92.969\n",
      "\n",
      "Epoch 144, Validation Loss= 3.369, validation Accuracy= 46.000%\n",
      "Epoch 144, Average Training Loss= 0.260, Average Training Accuracy= 93.248%\n",
      "\n",
      "Iter 0, Loss= 0.253, Accuracy= 95.312\n",
      "Iter 20, Loss= 0.286, Accuracy= 91.406\n",
      "Iter 40, Loss= 0.203, Accuracy= 96.094\n",
      "Iter 60, Loss= 0.291, Accuracy= 90.625\n",
      "\n",
      "Epoch 145, Validation Loss= 3.219, validation Accuracy= 46.200%\n",
      "Epoch 145, Average Training Loss= 0.271, Average Training Accuracy= 93.047%\n",
      "\n",
      "Iter 0, Loss= 0.312, Accuracy= 92.188\n",
      "Iter 20, Loss= 0.289, Accuracy= 92.188\n",
      "Iter 40, Loss= 0.230, Accuracy= 94.531\n",
      "Iter 60, Loss= 0.243, Accuracy= 94.531\n",
      "\n",
      "Epoch 146, Validation Loss= 3.488, validation Accuracy= 45.000%\n",
      "Epoch 146, Average Training Loss= 0.241, Average Training Accuracy= 94.241%\n",
      "\n",
      "Iter 0, Loss= 0.262, Accuracy= 93.750\n",
      "Iter 20, Loss= 0.196, Accuracy= 96.875\n",
      "Iter 40, Loss= 0.221, Accuracy= 95.312\n",
      "Iter 60, Loss= 0.259, Accuracy= 92.188\n",
      "\n",
      "Epoch 147, Validation Loss= 3.611, validation Accuracy= 44.500%\n",
      "Epoch 147, Average Training Loss= 0.230, Average Training Accuracy= 94.520%\n",
      "\n",
      "Iter 0, Loss= 0.243, Accuracy= 96.094\n",
      "Iter 20, Loss= 0.213, Accuracy= 96.094\n",
      "Iter 40, Loss= 0.217, Accuracy= 96.094\n",
      "Iter 60, Loss= 0.201, Accuracy= 95.312\n",
      "\n",
      "Epoch 148, Validation Loss= 3.729, validation Accuracy= 44.800%\n",
      "Epoch 148, Average Training Loss= 0.229, Average Training Accuracy= 94.699%\n",
      "\n",
      "Iter 0, Loss= 0.230, Accuracy= 94.531\n",
      "Iter 20, Loss= 0.234, Accuracy= 94.531\n",
      "Iter 40, Loss= 0.293, Accuracy= 90.625\n",
      "Iter 60, Loss= 0.198, Accuracy= 94.531\n",
      "\n",
      "Epoch 149, Validation Loss= 3.647, validation Accuracy= 44.100%\n",
      "Epoch 149, Average Training Loss= 0.217, Average Training Accuracy= 95.100%\n",
      "\n",
      "Iter 0, Loss= 0.146, Accuracy= 97.656\n",
      "Iter 20, Loss= 0.187, Accuracy= 96.875\n",
      "Iter 40, Loss= 0.224, Accuracy= 96.094\n",
      "Iter 60, Loss= 0.202, Accuracy= 96.094\n",
      "\n",
      "Epoch 150, Validation Loss= 3.610, validation Accuracy= 46.400%\n",
      "Epoch 150, Average Training Loss= 0.218, Average Training Accuracy= 95.268%\n",
      "\n",
      "Iter 0, Loss= 0.228, Accuracy= 94.531\n",
      "Iter 20, Loss= 0.244, Accuracy= 93.750\n",
      "Iter 40, Loss= 0.204, Accuracy= 96.094\n",
      "Iter 60, Loss= 0.211, Accuracy= 95.312\n",
      "\n",
      "Epoch 151, Validation Loss= 3.593, validation Accuracy= 45.500%\n",
      "Epoch 151, Average Training Loss= 0.235, Average Training Accuracy= 94.252%\n",
      "\n",
      "Iter 0, Loss= 0.280, Accuracy= 92.969\n",
      "Iter 20, Loss= 0.245, Accuracy= 92.188\n",
      "Iter 40, Loss= 0.178, Accuracy= 97.656\n",
      "Iter 60, Loss= 0.157, Accuracy= 99.219\n",
      "\n",
      "Epoch 152, Validation Loss= 3.811, validation Accuracy= 44.600%\n",
      "Epoch 152, Average Training Loss= 0.225, Average Training Accuracy= 95.312%\n",
      "\n",
      "Iter 0, Loss= 0.202, Accuracy= 94.531\n",
      "Iter 20, Loss= 0.200, Accuracy= 95.312\n",
      "Iter 40, Loss= 0.240, Accuracy= 96.094\n",
      "Iter 60, Loss= 0.211, Accuracy= 96.094\n",
      "\n",
      "Epoch 153, Validation Loss= 3.715, validation Accuracy= 44.900%\n",
      "Epoch 153, Average Training Loss= 0.216, Average Training Accuracy= 95.469%\n",
      "\n",
      "Iter 0, Loss= 0.206, Accuracy= 96.094\n",
      "Iter 20, Loss= 0.232, Accuracy= 95.312\n",
      "Iter 40, Loss= 0.199, Accuracy= 95.312\n",
      "Iter 60, Loss= 0.208, Accuracy= 95.312\n",
      "\n",
      "Epoch 154, Validation Loss= 3.839, validation Accuracy= 44.100%\n",
      "Epoch 154, Average Training Loss= 0.210, Average Training Accuracy= 95.424%\n",
      "\n",
      "Iter 0, Loss= 0.177, Accuracy= 97.656\n",
      "Iter 20, Loss= 0.293, Accuracy= 94.531\n",
      "Iter 40, Loss= 0.202, Accuracy= 96.094\n",
      "Iter 60, Loss= 0.188, Accuracy= 96.875\n",
      "\n",
      "Epoch 155, Validation Loss= 3.656, validation Accuracy= 44.900%\n",
      "Epoch 155, Average Training Loss= 0.213, Average Training Accuracy= 95.603%\n",
      "\n",
      "Iter 0, Loss= 0.149, Accuracy= 98.438\n",
      "Iter 20, Loss= 0.278, Accuracy= 92.969\n",
      "Iter 40, Loss= 0.192, Accuracy= 95.312\n",
      "Iter 60, Loss= 0.214, Accuracy= 96.094\n",
      "\n",
      "Epoch 156, Validation Loss= 3.895, validation Accuracy= 44.400%\n",
      "Epoch 156, Average Training Loss= 0.206, Average Training Accuracy= 95.792%\n",
      "\n",
      "Iter 0, Loss= 0.247, Accuracy= 93.750\n",
      "Iter 20, Loss= 0.175, Accuracy= 95.312\n",
      "Iter 40, Loss= 0.155, Accuracy= 96.875\n",
      "Iter 60, Loss= 0.129, Accuracy= 99.219\n",
      "\n",
      "Epoch 157, Validation Loss= 4.128, validation Accuracy= 45.000%\n",
      "Epoch 157, Average Training Loss= 0.190, Average Training Accuracy= 96.217%\n",
      "\n",
      "Iter 0, Loss= 0.220, Accuracy= 96.094\n",
      "Iter 20, Loss= 0.232, Accuracy= 94.531\n",
      "Iter 40, Loss= 0.193, Accuracy= 96.094\n",
      "Iter 60, Loss= 0.205, Accuracy= 95.312\n",
      "\n",
      "Epoch 158, Validation Loss= 3.977, validation Accuracy= 44.500%\n",
      "Epoch 158, Average Training Loss= 0.209, Average Training Accuracy= 95.871%\n",
      "\n",
      "Iter 0, Loss= 0.185, Accuracy= 95.312\n",
      "Iter 20, Loss= 0.246, Accuracy= 96.094\n",
      "Iter 40, Loss= 0.227, Accuracy= 96.094\n",
      "Iter 60, Loss= 0.254, Accuracy= 92.188\n",
      "\n",
      "Epoch 159, Validation Loss= 3.929, validation Accuracy= 43.200%\n",
      "Epoch 159, Average Training Loss= 0.194, Average Training Accuracy= 96.328%\n",
      "\n",
      "Iter 0, Loss= 0.161, Accuracy= 97.656\n",
      "Iter 20, Loss= 0.197, Accuracy= 96.875\n",
      "Iter 40, Loss= 0.196, Accuracy= 97.656\n",
      "Iter 60, Loss= 0.198, Accuracy= 96.094\n",
      "\n",
      "Epoch 160, Validation Loss= 4.018, validation Accuracy= 44.500%\n",
      "Epoch 160, Average Training Loss= 0.204, Average Training Accuracy= 95.915%\n",
      "\n",
      "Iter 0, Loss= 0.184, Accuracy= 96.094\n",
      "Iter 20, Loss= 0.172, Accuracy= 97.656\n",
      "Iter 40, Loss= 0.176, Accuracy= 97.656\n",
      "Iter 60, Loss= 0.169, Accuracy= 98.438\n",
      "\n",
      "Epoch 161, Validation Loss= 4.120, validation Accuracy= 44.500%\n",
      "Epoch 161, Average Training Loss= 0.189, Average Training Accuracy= 96.685%\n",
      "\n",
      "Iter 0, Loss= 0.239, Accuracy= 94.531\n",
      "Iter 20, Loss= 0.160, Accuracy= 96.094\n",
      "Iter 40, Loss= 0.219, Accuracy= 93.750\n",
      "Iter 60, Loss= 0.201, Accuracy= 96.094\n",
      "\n",
      "Epoch 162, Validation Loss= 4.056, validation Accuracy= 44.400%\n",
      "Epoch 162, Average Training Loss= 0.197, Average Training Accuracy= 96.317%\n",
      "\n",
      "Iter 0, Loss= 0.144, Accuracy= 98.438\n",
      "Iter 20, Loss= 0.206, Accuracy= 96.094\n",
      "Iter 40, Loss= 0.242, Accuracy= 94.531\n",
      "Iter 60, Loss= 0.151, Accuracy= 98.438\n",
      "\n",
      "Epoch 163, Validation Loss= 3.980, validation Accuracy= 44.400%\n",
      "Epoch 163, Average Training Loss= 0.203, Average Training Accuracy= 96.116%\n",
      "\n",
      "Iter 0, Loss= 0.171, Accuracy= 97.656\n",
      "Iter 20, Loss= 0.161, Accuracy= 97.656\n",
      "Iter 40, Loss= 0.187, Accuracy= 97.656\n",
      "Iter 60, Loss= 0.173, Accuracy= 96.094\n",
      "\n",
      "Epoch 164, Validation Loss= 4.056, validation Accuracy= 44.500%\n",
      "Epoch 164, Average Training Loss= 0.191, Average Training Accuracy= 96.685%\n",
      "\n",
      "Iter 0, Loss= 0.188, Accuracy= 96.875\n",
      "Iter 20, Loss= 0.207, Accuracy= 95.312\n",
      "Iter 40, Loss= 0.147, Accuracy= 99.219\n",
      "Iter 60, Loss= 0.219, Accuracy= 95.312\n",
      "\n",
      "Epoch 165, Validation Loss= 4.089, validation Accuracy= 45.000%\n",
      "Epoch 165, Average Training Loss= 0.191, Average Training Accuracy= 96.529%\n",
      "\n",
      "Iter 0, Loss= 0.173, Accuracy= 97.656\n",
      "Iter 20, Loss= 0.181, Accuracy= 98.438\n",
      "Iter 40, Loss= 0.222, Accuracy= 94.531\n",
      "Iter 60, Loss= 0.142, Accuracy= 98.438\n",
      "\n",
      "Epoch 166, Validation Loss= 3.885, validation Accuracy= 45.600%\n",
      "Epoch 166, Average Training Loss= 0.191, Average Training Accuracy= 96.462%\n",
      "\n",
      "Iter 0, Loss= 0.171, Accuracy= 97.656\n",
      "Iter 20, Loss= 0.159, Accuracy= 97.656\n",
      "Iter 40, Loss= 0.160, Accuracy= 98.438\n",
      "Iter 60, Loss= 0.220, Accuracy= 96.094\n",
      "\n",
      "Epoch 167, Validation Loss= 4.239, validation Accuracy= 44.300%\n",
      "Epoch 167, Average Training Loss= 0.175, Average Training Accuracy= 97.031%\n",
      "\n",
      "Iter 0, Loss= 0.155, Accuracy= 98.438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20, Loss= 0.217, Accuracy= 94.531\n",
      "Iter 40, Loss= 0.215, Accuracy= 94.531\n",
      "Iter 60, Loss= 0.165, Accuracy= 98.438\n",
      "\n",
      "Epoch 168, Validation Loss= 4.078, validation Accuracy= 46.100%\n",
      "Epoch 168, Average Training Loss= 0.179, Average Training Accuracy= 96.864%\n",
      "\n",
      "Iter 0, Loss= 0.131, Accuracy= 99.219\n",
      "Iter 20, Loss= 0.269, Accuracy= 97.656\n",
      "Iter 40, Loss= 0.192, Accuracy= 96.094\n",
      "Iter 60, Loss= 0.249, Accuracy= 95.312\n",
      "\n",
      "Epoch 169, Validation Loss= 4.068, validation Accuracy= 45.500%\n",
      "Epoch 169, Average Training Loss= 0.182, Average Training Accuracy= 96.931%\n",
      "\n",
      "Iter 0, Loss= 0.217, Accuracy= 95.312\n",
      "Iter 20, Loss= 0.141, Accuracy= 98.438\n",
      "Iter 40, Loss= 0.187, Accuracy= 97.656\n",
      "Iter 60, Loss= 0.274, Accuracy= 94.531\n",
      "\n",
      "Epoch 170, Validation Loss= 4.304, validation Accuracy= 45.300%\n",
      "Epoch 170, Average Training Loss= 0.169, Average Training Accuracy= 97.355%\n",
      "\n",
      "Iter 0, Loss= 0.146, Accuracy= 99.219\n",
      "Iter 20, Loss= 0.185, Accuracy= 96.875\n",
      "Iter 40, Loss= 0.202, Accuracy= 97.656\n",
      "Iter 60, Loss= 0.248, Accuracy= 94.531\n",
      "\n",
      "Epoch 171, Validation Loss= 4.163, validation Accuracy= 46.500%\n",
      "Epoch 171, Average Training Loss= 0.186, Average Training Accuracy= 96.629%\n",
      "\n",
      "Iter 0, Loss= 0.156, Accuracy= 97.656\n",
      "Iter 20, Loss= 0.127, Accuracy= 100.000\n",
      "Iter 40, Loss= 0.126, Accuracy= 100.000\n",
      "Iter 60, Loss= 0.211, Accuracy= 96.094\n",
      "\n",
      "Epoch 172, Validation Loss= 4.164, validation Accuracy= 45.700%\n",
      "Epoch 172, Average Training Loss= 0.185, Average Training Accuracy= 96.730%\n",
      "Early Stopping since best validation accuracy not increasing for 99 epochs.\n",
      "\n",
      "Optimization Finished!\n",
      "\n",
      "Best Validation Loss: 49.600%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: # Start Tensorflow Session\n",
    "    \n",
    "    saver = tf.train.Saver() \n",
    "    # Prepares variable for saving the model\n",
    "    sess.run(init) #initialize all variables\n",
    "    step = 1   \n",
    "    loss_list=[]\n",
    "    acc_list=[]\n",
    "    val_loss_list=[]\n",
    "    val_acc_list=[]\n",
    "    best_val_acc=0\n",
    "    prev_val_acc=0\n",
    "    patience = 99\n",
    "    impatience = 0\n",
    "    display_step = 20\n",
    "            \n",
    "    batch_size = 128\n",
    "    \n",
    "    while step <= epochs:\n",
    "        \n",
    "        total_loss=0\n",
    "        total_acc=0\n",
    "        total_val_loss = 0\n",
    "        total_val_acc = 0\n",
    "\n",
    "        batches_train_fact_stories,batches_train_questions,batches_train_answers = create_batches(train_fact_stories,train_questions,train_answers,batch_size)\n",
    "        \n",
    "        for i in xrange(len(batches_train_questions)):\n",
    "            \n",
    "            # Run optimization operation (backpropagation)\n",
    "            _,loss,acc,pred = sess.run([optimizer,cost,accuracy,prediction],\n",
    "                                       feed_dict={tf_facts: batches_train_fact_stories[i], \n",
    "                                                  tf_questions: batches_train_questions[i], \n",
    "                                                  tf_answers: batches_train_answers[i],\n",
    "                                                  keep_prob: 0.9})\n",
    "        \n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "                \n",
    "            if i%display_step == 0:\n",
    "                print \"Iter \"+str(i)+\", Loss= \"+\\\n",
    "                      \"{:.3f}\".format(loss)+\", Accuracy= \"+\\\n",
    "                      \"{:.3f}\".format(acc*100)\n",
    "                        \n",
    "        avg_loss = total_loss/len(batches_train_questions) \n",
    "        avg_acc = total_acc/len(batches_train_questions)  \n",
    "        \n",
    "        loss_list.append(avg_loss) \n",
    "        acc_list.append(avg_acc) \n",
    "\n",
    "        val_batch_size = 100 #(should be able to divide total no. of validation samples without remainder)\n",
    "        batches_val_fact_stories,batches_val_questions,batches_val_answers = create_batches(val_fact_stories,val_questions,val_answers,val_batch_size)\n",
    "        \n",
    "        for i in xrange(len(batches_val_questions)):\n",
    "            val_loss, val_acc = sess.run([cost, accuracy], \n",
    "                                         feed_dict={tf_facts: batches_val_fact_stories[i], \n",
    "                                                    tf_questions: batches_val_questions[i], \n",
    "                                                    tf_answers: batches_val_answers[i],\n",
    "                                                    keep_prob: 1})\n",
    "            total_val_loss += val_loss\n",
    "            total_val_acc += val_acc\n",
    "                      \n",
    "            \n",
    "        avg_val_loss = total_val_loss/len(batches_val_questions) \n",
    "        avg_val_acc = total_val_acc/len(batches_val_questions) \n",
    "             \n",
    "        val_loss_list.append(avg_val_loss) \n",
    "        val_acc_list.append(avg_val_acc) \n",
    "    \n",
    "\n",
    "        print \"\\nEpoch \" + str(step) + \", Validation Loss= \" + \\\n",
    "                \"{:.3f}\".format(avg_val_loss) + \", validation Accuracy= \" + \\\n",
    "                \"{:.3f}%\".format(avg_val_acc*100)+\"\"\n",
    "        print \"Epoch \" + str(step) + \", Average Training Loss= \" + \\\n",
    "              \"{:.3f}\".format(avg_loss) + \", Average Training Accuracy= \" + \\\n",
    "              \"{:.3f}%\".format(avg_acc*100)+\"\"\n",
    "        \n",
    "        impatience += 1\n",
    "            \n",
    "        if avg_val_acc >= best_val_acc: # When better accuracy is received than previous best validation accuracy\n",
    "            impatience = 0\n",
    "            best_val_acc = avg_val_acc # update value of best validation accuracy received yet.\n",
    "            saver.save(sess, 'DMN_Model_Backup/model.ckpt') # save_model including model variables (weights, biases etc.)\n",
    "            print \"Checkpoint created!\"  \n",
    "        \n",
    "        if impatience > patience:\n",
    "            print \"Early Stopping since best validation accuracy not increasing for \"+str(patience)+\" epochs.\"\n",
    "            break\n",
    "            \n",
    "        print \"\"\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "    \n",
    "        \n",
    "    print \"\\nOptimization Finished!\\n\"\n",
    "    \n",
    "    print \"Best Validation Loss: %.3f%%\"%((best_val_acc)*100)\n",
    "    \n",
    "    #The model can be run on test data set after this.\n",
    "    #val_loss_list, val_acc_list, loss_list and acc_list can be used for plotting. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving logs about change of training and validation loss and accuracy over epochs in another file.\n",
    "\n",
    "import h5py\n",
    "\n",
    "file = h5py.File('Training_logs_DMN_plus.h5','w')\n",
    "file.create_dataset('val_acc', data=np.array(val_acc_list))\n",
    "file.create_dataset('val_loss', data=np.array(val_loss_list))\n",
    "file.create_dataset('acc', data=np.array(acc_list))\n",
    "file.create_dataset('loss', data=np.array(loss_list))\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEPCAYAAABMTw/iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnCZ6pZTK5DTRK6VUJvf/8cjEmIDxNrgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f968ede6890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEPCAYAAABMTw/iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK6VUEaeJXimlirj/B3w/Px4mZdvJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96dcebc690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "log = h5py.File('Training_logs_DMN_plus.h5','r+') # Loading logs about change of training and validation loss and accuracy over epochs\n",
    "\n",
    "y1 = log['val_acc'][...]\n",
    "y2 = log['acc'][...]\n",
    "\n",
    "x = np.arange(1,len(y1)+1,1) # (1 = starting epoch, len(y1) = no. of epochs, 1 = step) \n",
    "\n",
    "plt.plot(x,y1,'b',label='Validation Accuracy') \n",
    "plt.plot(x,y2,'r',label='Training Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "y1 = log['val_loss'][...]\n",
    "y2 = log['loss'][...]\n",
    "\n",
    "plt.plot(x,y1,'b',label='Validation Loss')\n",
    "plt.plot(x,y2,'r',label='Training Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained weights for the model...\n",
      "INFO:tensorflow:Restoring parameters from DMN_Model_Backup/model.ckpt\n",
      "\n",
      "RESTORATION COMPLETE\n",
      "\n",
      "Testing Model Performance...\n",
      "\n",
      "Test Loss= 0.898, Test Accuracy= 48.100%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: # Begin session\n",
    "    \n",
    "    print 'Loading pre-trained weights for the model...'\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, 'DMN_Model_Backup/model.ckpt')\n",
    "    sess.run(tf.global_variables())\n",
    "    print '\\nRESTORATION COMPLETE\\n'\n",
    "    \n",
    "    print 'Testing Model Performance...'\n",
    "    \n",
    "    total_test_loss = 0\n",
    "    total_test_acc = 0\n",
    "    \n",
    "    test_batch_size = 100 #(should be able to divide total no. of test samples without remainder)\n",
    "    batches_test_fact_stories,batches_test_questions,batches_test_answers = create_batches(test_fact_stories,test_questions,test_answers,test_batch_size)\n",
    "        \n",
    "    for i in xrange(len(batches_test_questions)):\n",
    "        test_loss, test_acc = sess.run([cost, accuracy], \n",
    "                                        feed_dict={tf_facts: batches_test_fact_stories[i], \n",
    "                                                   tf_questions: batches_test_questions[i], \n",
    "                                                   tf_answers: batches_test_answers[i],\n",
    "                                                   keep_prob: 1})\n",
    "        total_test_loss += test_loss\n",
    "        total_test_acc += test_acc\n",
    "                      \n",
    "            \n",
    "    avg_test_loss = total_test_loss/len(batches_test_questions) \n",
    "    avg_test_acc = total_test_acc/len(batches_test_questions) \n",
    "\n",
    "\n",
    "    print \"\\nTest Loss= \" + \\\n",
    "          \"{:.3f}\".format(avg_test_loss) + \", Test Accuracy= \" + \\\n",
    "          \"{:.3f}%\".format(avg_test_acc*100)+\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
